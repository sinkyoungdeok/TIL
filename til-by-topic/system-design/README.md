- [1장 사용자 수에 따른 규모 확장성](#1장-사용자-수에-따른-규모-확장성)
  - [단일 서버](#단일-서버)
  - [데이터베이스](#데이터베이스)
  - [수직적 규모 확장 vs 수평적 규모 확장](#수직적-규모-확장-vs-수평적-규모-확장)
  - [캐시](#캐시)
  - [CDN](#cdn)
  - [무상태(stateless) 웹 계층](#무상태stateless-웹-계층)
  - [데이터 센터](#데이터-센터)
  - [메시지 큐](#메시지-큐)
  - [로그, 메트릭, 그리고 자동화](#로그-메트릭-그리고-자동화)
  - [데이터베이스의 규모 확장](#데이터베이스의-규모-확장)
  - [백만 사용자, 그리고 그 이상](#백만-사용자-그리고-그-이상)
- [2장 개략적인 규모 추정](#2장-개략적인-규모-추정)
  - [2의 제곱수](#2의-제곱수)
  - [모든 프로그래머가 알아야 하는 응답지연 값](#모든-프로그래머가-알아야-하는-응답지연-값)
  - [가용성에 관계된 수치들](#가용성에-관계된-수치들)
  - [예제: 트위터 QPS와 저장소 요구량 측정](#예제-트위터-qps와-저장소-요구량-측정)
  - [팁](#팁)
- [3. 시스템 설계 면접 공략법](#3-시스템-설계-면접-공략법)
  - [효과적 면접을 위한 4단계 접근법](#효과적-면접을-위한-4단계-접근법)
- [4. 처리율 제한 장치의 설계](#4-처리율-제한-장치의-설계)
  - [1단계: 문제 이해 및 설계 범위 확정](#1단계-문제-이해-및-설계-범위-확정)
  - [2단계: 개략적 설계안 제시 및 동의 구하기](#2단계-개략적-설계안-제시-및-동의-구하기)
  - [3단계: 상세 설계](#3단계-상세-설계)
  - [4단계: 마무리](#4단계-마무리)
- [5. 안정 해시 설계](#5-안정-해시-설계)
  - [해시 키 재배치 문제](#해시-키-재배치-문제)
  - [안정 해시](#안정-해시)
  - [마치며](#마치며)
- [6. 키-값 저장소 설계](#6-키-값-저장소-설계)
  - [문제 이해 및 설계 범위 확정](#문제-이해-및-설계-범위-확정)
  - [단일 서버 키-값 저장소](#단일-서버-키-값-저장소)
  - [분산 키-값 저장소](#분산-키-값-저장소)
  - [요약](#요약)
- [7. 분산 시스템을 위한 유일 ID 생성기 설계](#7-분산-시스템을-위한-유일-id-생성기-설계)
  - [1단계: 문제 이해 및 설계 범위 확정](#1단계-문제-이해-및-설계-범위-확정-1)
  - [2단계: 개략적 설계안 제시 및 동의 구하기](#2단계-개략적-설계안-제시-및-동의-구하기-1)
  - [3단계: 상세 설계](#3단계-상세-설계-1)
  - [4단계: 마무리](#4단계-마무리-1)
- [9. 웹 크롤러 설계](#9-웹-크롤러-설계)
  - [1단계: 문제 이해 및 설계 범위 확정](#1단계-문제-이해-및-설계-범위-확정-2)

## 1장 사용자 수에 따른 규모 확장성 
한 명의 사용자를 지원하는 시스템에서 시작하여, 최종적으로는 몇백만 사용자를 지원하는 시스템을 설계해 볼 것이다.


### 단일 서버

<img width="768" alt="image" src="https://github.com/sinkyoungdeok/TIL/assets/28394879/9b648507-0bfa-4a01-9e48-14fd42e7fcc1">

웹, 앱, 데이터베이스, 캐시 등이 전부 서버 한대에서 실행된다.

사용자 요청 처리 흐름은 다음과 같다. 

1. 도메인이름을 이용하여 웹사이트에 접속. 
2. 도메인 이름을 DNS(Domain Name Service)에 질의하여 IP 주소로 변환 
3. 해당 IP주소로 HTTP 요청이 전달
4. 웹서버에서 HTML or JSON 응답 반환 



### 데이터베이스

<img width="768" alt="image" src="https://github.com/sinkyoungdeok/TIL/assets/28394879/262181b3-a2e9-4c0e-8529-a68fce7bdd9a">

- 사용자가 늘면서 하나는 웹/모바일 트래픽 처리 용도의 서버, 다른 하나는 데이터베이스용 서버로 분리했다.
- 분리함으로써 각각을 독립적으로 확장해 나갈 수 있게 됐다.

**어떤 데이터베이스를 사용할 것인가?** 
- RDB vs NoSql 에서 고른다.
- RDB: Mysql, Oracle, PostgreSQL 등 
- NoSQL: CouchDB, Neo4j, Cassandra, HBase, Amazon DynamoDB 등
- NoSQL은 네 부류로 나눌 수 있다.
  - key-value store
  - graph store
  - column store
  - document store
- RDB는 조인 연산을 지원하는 반면, NoSQL은 조인 연산을 지원하지 않는다. 
- 아래 케이스에선 NoSQL를 고려해보자.
  - 아주 낮은 응답 지연시간 필요
  - 데이터가 비정형임
  - 데이터를 serialize, deserialize 할 수 있기만 하면 됨
  - 

### 수직적 규모 확장 vs 수평적 규모 확장
- 스케일업(수직 = vertical scaling): 서버에 고사양 자원을 추가하는 행위
- 스케일 아웃(수평 = scale out): 더 많은 서버를 추가
- 트래픽 양이 적을 때는 스케일업이 좋은 선택이고 단순함이 큰 장점인 반면에 심각한 단점이 있다.
  - 한 대의 서버에 CPU나 메모리를 무한대로 증설 할 수 없으므로 한계가 있다.
  - 장애에 대한 자동복구 방안이나 다중화 방안을 제시할 수 없다.
- 대규모 애플리케이션에서는 scale out이 더 적절하다.

트래픽이 몰릴 때에는 load balancer를 도입해보자.

**로드밸런서**  

<img width="728" alt="image" src="https://github.com/sinkyoungdeok/TIL/assets/28394879/08338d86-af45-481b-8319-a1e5da13dd38">

- 사용자는 로드밸런서의 공개 IP 주소로 접속한다. 
- 부하 분산 집합에 웹 서버를 하나 더 추가하고 나면 장애를 자동복구하지 못하는 문제(no failover)는 해소되며, 웹 계층의 가용성(availability)은 향상된다.
  - 서버한대가 다운되면(offline) 다른 서버로 트래픽이 전송된다.
  - 트래픽이 급증하면 서버 1대이상을 추가하기만 하면 된다. 

웹 계층은 이제 괜찮은데, DB는 하나 뿐이고 장애의 자동복구나 다중화를 지원하지 않는다.  
DB 다중화는 이런 문제를 해결하는 보편화된 기술이다.


**데이터베이스 다중화**  

- 보통 DB는 서버 사이에 master-slave 관계를 설정하고 데이터 원본은 주 서버에, 사본은 부 서버에 저장한다.
- 쓰기 연산은 마스터에서만 지원한다.
- slave DB는 master DB 로부터 사본을 전달 받으며, 읽기 연산만을 지원한다. 
- 대부분의 애플리케이션은 읽기 연산 비중이 쓰기 연산보다 훨씬 높기 때문에, slave DB 수를 더 많이 구성한다.


<img width="816" alt="image" src="https://github.com/sinkyoungdeok/TIL/assets/28394879/6c43457a-2c25-4da9-960a-5939cd149818">

- 데이터베이스를 다중화하면 다음과 같은 이득이 있다. 
  - 더 나은 성능: 병렬로 처리될 수 있는 query 수가 늘어나서 성능이 올라간다. 
  - 안정성: DB 일부가 죽더라도 데이터는 보존된다. 데이터를 지역적으로 떨어진 여러 장소에 다중화 시킬수도 있다.
  - 가용성: 데이터를 여러 지역에 복제해 둠으로써, 하나의 DB에 장애가 발생해도 다른 서버에 있는 데이터를 가져와서 서비스할 수 있다. 
- 데이터베이스 한대가 다운되면 어떤일이 벌어질까?
  - slave DB가 한대인데 다운된경우
    - 읽기 연산이 일시적으로 master DB로 감.
    - 새로운 slave DB가 장애서버를 대체 
  - slave DB가 여러대인데 다운된경우
    - 읽기 연산이 나머지 slave DB로 간다.
    - 새로운 slave DB가 장애서버를 대체 
  - master DB가 한대인데 다운된경우
    - slave DB가 master DB로 승격된다.
    - 모든 연산은 새로운 master DB로 수행된다.
    - 그리고 새로운 slave DB가 추가된다. 
    - 부 서버에 보관된 데이터가 최신 상태가 아닐 수 있는데, 이 때에는 없는 데이터에 대해서 복구 스크립트를 돌려서 추가해야 한다. 
    - 다중 마스터(multi-masters)나 원형 다중화(circular replication) 방식을 도입하면 이런 상황을 대처하는데 도움이 되지만 구성이 훨씬 복잡해진다. 

<img width="868" alt="image" src="https://github.com/sinkyoungdeok/TIL/assets/28394879/652e7778-0ae2-490f-84d8-94224e4cb10d">

- 로드밸런서 + DB 다중화를 고려한 설계 


다음은 응답시간을 개선해보자.  
응답시간은 캐시를 붙이고 정적 컨텐츠를 CDN으로 옮기면 개선할 수 있다.


### 캐시
- 값비싼 연산 결과 또는 자주 참조되는 데이터를 메모리 안에 두고, 뒤이은 요청이 빨리 처리될 수 있도록 하는 저장소다.

**캐시 계층**  
- 캐시 계층은 데이터가 잠시 보관되는 곳으로 DB보다 훨씬 빠르다.
- 성능 개선 뿐 아니라 DB 부하를 줄일 수 있고, 캐시 계층을 독립적으로 확장시키는 것도 가능하다. 

<img width="802" alt="image" src="https://github.com/sinkyoungdeok/TIL/assets/28394879/cc0b0344-f7fb-44ac-83a2-fd3573a03173">

- 이러한 캐시 전략을 읽기 주도형 캐시 전략이라고 부른다.
- 이것 이외에도 다양한 캐시 전략이 있는데, 캐시할 데이터 종류, 크기, 액세스 패턴에 맞는 캐시 전략을 선택하면 된다.

**캐시 사용 시 유의할 점**  
- 캐시는 어떤 상황에 바람직한가? 데이터 갱신은 자주 일어나지 않지만 참조는 빈번하게 일어난다면 고려해보자.
- 어떤 데이터를 캐시에 두어야 하는가? 캐시 데이터는 휘발성 메모리에 두므로, 영속적으로 보관할 데이터를 캐시에 두는 것은 바람직하지 않다. 
- 캐시에 보관된 데이터는 어떻게 만료 되는가? 이에 대한 정책을 마련해 두는 것이 좋다. 만료 기한은 너무 짧거나 길면 곤란하다. DB를 너무 자주 읽거나, 원본과 차이날 수 있기 때문이다.
- 일관성은 어떻게 유지되는가? 저장소의 원본을 갱신하는 연산과 캐시를 갱신하는 연산이 단일 트랜잭션으로 처리되지 않는 경우 일관성은 깨질 수 있다. 
- 장애에는 어떻게 대처할 것인가? 캐시 서버를 한 대만 두는 경우 SPOF가 될 수 있다. 특정 지점의 장애가 전체시스템의 동작을 중단시킬 수 있는 경우가 SPOF인데, SPOF를 피하려면 여러 지역에 걸쳐 캐시 서버를 분산시켜야 한다.

<img width="781" alt="image" src="https://github.com/sinkyoungdeok/TIL/assets/28394879/5044d3ad-e628-4ac6-9072-5cef4f2de623">

- 캐시 메모리는 얼마나 크게 잡을 것인가? 캐시 메모리가 너무 작으면 데이터가 너무 자주 캐시에서 밀려나버려 캐시 성능이 저하될 수 있다.
- 데이터 방출(eviction) 정책은 무엇인가? 가장 널리 쓰이는 것은 LRU(마지막으로 사용된 데이터를 내보냄) 이다. LFU(사용 빈도가 가장 낮은 데이터를 내보내는 정책)이나 FIFO같은 것도 있는데 경우에 맞게 적용하자.


### CDN

- 정적 콘텐츠를 전송하는 데 쓰이는, 지리적으로 분산된 서버의 네트워크이다. 
- 이미지, 비디오, CSS, js 파일 등을 캐시할 수 있다. 
- request path, query string, cookie, request header 등의 정보에 기반하여 HTML 페이지를 캐시하는 것이다.

<img width="781" alt="image" src="https://github.com/sinkyoungdeok/TIL/assets/28394879/62d15673-538f-4f8c-8b6b-7a9ee6fb3589">

- 어떤 사용자가 웹사이트를 방문하면, 그 사용자에게 가장 가까운 CDN 서버가 정적 콘텐츠를 전달한다.


<img width="781" alt="image" src="https://github.com/sinkyoungdeok/TIL/assets/28394879/d81941b6-ee99-4060-a3c4-adab36acc354">


**CDN 사용 시 고려해야 할 사항**  
- 비용: CDN으로 들어가고 나가는 데이터 전송 양에 따라 요금을 내게 된다. 자주 사용하지 않은 컨텐츠를 캐싱하는 것은 이득이 크지 않으므로 CDN에서 빼는 것을 고려하자.
- 적절한 만료 시한 설정: 시의성이 중요한(time-sensitive) 컨텐츠의 경우 만료 시점을 잘 정해야 한다.
- CDN 장애에 대한 대처 방안: CDN이 응답 하지 않을 경우, 문제를 감지하여 원본 서버로부터 직접 컨텐츠를 가져오도록 클라이언트를 구성하는것이 필요할 수 있다.
- 컨텐츠 무효화 방법: 아직 만료되지 않은 컨텐츠라 하더라도 아래 방법들 중 하나를 쓰면 CDN에서 제거할 수 있다.
  - CDN 서비스 사업자가 제공하는 API 사용 
  - 컨텐츠의 다른 버전을 서비스하도록 오브젝트 버저닝이용. 컨텐츠의 새로운 버전을 지정하기 위해서 URL 마지막에 버전 번호를 인자로 주면 된다. ex) image.png?v=2 

<img width="781" alt="image" src="https://github.com/sinkyoungdeok/TIL/assets/28394879/5d1f04cf-70b2-46f2-873e-2aac12bb7ceb">

- CDN과 캐시가 추가된 설계
- 변화된 부분
  - 정적컨텐츠는 CDN을 통해 제공하여 더 나은 성능을 보장한다.
  - 캐시가 데이터베이스 부하를 줄여준다.

### 무상태(stateless) 웹 계층 
- 웹 계층을 수평적으로 확장하는 방법을 고민해보자. 
- 이를 위해서는 상태 정보(사용자 세션 데이터와 같은)를 웹 계층에서 제거해야 한다.
- 상태 정보는 RDB, NoSQL 같은 지속성 저장소에 보관하고, 필요할 때 가져오도록 하자.
- 이렇게 구성된 웹 계층을 무상태 웹 계층이라 부른다.

**상태 정보 의존적인 아키텍처**  
- 상태 정보를 보관하는 서버와 그렇지 않은 서버 사이에는 몇가지 중요한 차이가 있다.
- 상태 정보를 보관하는 서버는 상태 정보를 요청들 사이에 공유되도록 한다. (무상태 서버에는 이런 장치가 없다)

<img width="792" alt="image" src="https://github.com/sinkyoungdeok/TIL/assets/28394879/833392fb-a63b-44fb-aa75-39b4b2b76660">

- 같은 클라이언트로부터의 요청은 항상 같은 서버로 전송되어야 한다.
- 대부분의 로드밸런서가 이를 지원하기 위해 고정 세션이라는 기능을 제공하는데, 이는 로드밸런서에 부담을 준다.
- 게다가 로드밸런서 뒷단에 서버를 추가하거나 제거하기도 까다로워지고, 서버의 장애를 처리하기도 복잡해진다.

**무상태 아키텍처**  

<img width="624" alt="image" src="https://github.com/sinkyoungdeok/TIL/assets/28394879/fbd1e93a-3dc9-44bf-8f4e-1b1304645a5a">

- 이 구조에서는 HTTP 요청이 어떤 웹 서버로도 전달될 수 있다. 
- 웹 서버는 상태 정보가 필요할 경우 공유 저장소로부터 데이터를 가져온다. 
- 따라서 상태 정보는 웹 서버로부터 물리적으로 분리되어 있고, 구조가 단순하고 안정적이며 규모 확장이 쉬워진다.

<img width="854" alt="image" src="https://github.com/sinkyoungdeok/TIL/assets/28394879/28e3d617-a065-4051-8dc0-5d260f515a23">

- 세션 데이터를 웹 계층에서 분리하고 지속성 데이터 보관소에 저장하도록 만들었다.
- 이 공유 저장소는 RDB가 될수도 있고, Memcached/Redis 같은 캐시 시스템일 수도 있고 NoSQL일 수도 있다.
- 여기서는 NoSQL을 사용하였으며, 규모 확장이 간편해서다.


가용성을 높이고 전 세계 어디서도 쾌적하게 사용할 수 있도록 하려면  
여러 데이터 센터를 지원하는 것이 필수다.

### 데이터 센터

<img width="854" alt="image" src="https://github.com/sinkyoungdeok/TIL/assets/28394879/d87c323d-99d8-48be-862e-314b314af0cf">

- 두 개의 데이터 센터를 이용하는 사례다.
- 장애가 없는 상황에서 사용자는 가장 가까운 데이터 센터로 안내되는데, 이것을 지리적 라우팅이라고(geoDNS-routing or geo-routing) 부른다.
- 지리적 라우팅에서의 geoDNS는 사용자의 위치에 따라 도메인 이름을 어떤 IP 주소로 변환할지 결정할 수 있도록 해주는 DNS 서비스다.

<img width="854" alt="image" src="https://github.com/sinkyoungdeok/TIL/assets/28394879/0345acc1-a6c7-444b-8f52-a3f313d2265a">

- 데이터 센터 중 하나에 심각한 장애가 발생하면 모든 트래픽이 장애가 없는 데이터 센터로 전송된다.
- 위 그림은 US-West에 장애가 발생하여, US-East로 전송되는 상황이다.

이 사례와 같은 다중 데이터센터 아키텍처를 만들려면 몇가지 기술적 난제를 해결해야 한다.
- 트래픽 우회: 올바른 데이터 센터로 트래픽을 보내는 효과적인 방법을 찾아야한다. ex) GeoDNS
- 데이터 동기화: 데이터 센터마다 별도의 DB를 사용하면, 장애가 자동으로 복구되어 트래픽이 다른 DB로 우회되도, 해당 데이터센터에는 찾는 데이터가 없을 수 있다. 이런 상황을 막는 보편적 전략은 데이터를 여러 데이터센터에 걸쳐 다중화하는 것이다.
- 테스트와 배포: 웹 사이트 또는 애플리케이션을 여러 위치에서 테스트해보는 것이 중요하다. 또, 자동화된 배포 도구는 모든 데이터 센터에 동일한 서비스가 설치되도록 하는 데 중요한 역할을 한다.

시스템을 더 큰 규모로 확장하기 위해서는 시스템의 컴포넌트를 분리하여, 각기 독립적으로 확장될 수 있도록 하여야 한다.  
메시지 큐는 많은 실제 분산 시스템이 이 문제를 풀기 위해 채용하고 있는 핵심적 전략 가운데 하나다. 

### 메시지 큐 
- 메시지의 무손실을 보장하는, 비동기 통신을 지원하는 컴포넌트다. 
- 메시지의 버퍼 역할을 하며, 비동기적으로 전송한다. 
- 메시지 큐를 이용하면 서비스 또는 서버 간 결합이 느슨해져서, 규모 확장성이 보장되어야 하는 안정적 애플리케이션을 구성하기 좋다. 


<img width="759" alt="image" src="https://github.com/sinkyoungdeok/TIL/assets/28394879/737f8c57-6d92-4747-92f6-b7f087553fbb">

- 이미지의 크로핑, 샤프닝, 블러핑 등을 지원하는 사진 보정 애플리케이션을 만든다고 해 보자.
- 보정은 시간이 오래 걸릴 수 있는 프로세스이므로 비동기적으로 처리하면 편하다.
- 웹 서버는 사진 보정 작업을 메시지 큐에 넣는다. 
- 사진 보정 작업(worker) 프로세스들은 이 작업을 메시지 큐에서 꺼내어 비동기적으로 완료한다.
- 생산자와 소비자 서비스의 규모는 각기 독립적으로 확장될 수 있다. 
- 큐의 크기가  커지면 작업 프로세스를 늘리고, 큐가 항상 비어 있는 상태라면 작업 프로세스의 수를 줄일 수 있다. 

### 로그, 메트릭, 그리고 자동화 
- 소규모 웹 사이트에선 필요 없지만, 웹사이트와 함께 사업 규모가 커지고나면 로그나 메트릭, 자동화 같은 도구에 필수적으로 투자해야 한다.
- 로그: 에러 로그를 서버 단위로 모니터링 할 수도 있지만, 로그를 단일 서비스로 모아주는 도구를 활용하면 더 편리하게 검색하고 조회할 수 있다. 
- 메트릭
  - 호스트 단위 메트릭: CPU, 메모리, 디스크 I/O에 관한 메트릭
  - 종합 메트릭: DB 계층의 성능, 캐시 계층의 성능 
  - 핵심 비즈니스 메트릭: 일별 능동 사용자, 수익, 재방문 등
- 자동화: 시스템이 크고 복잡해지면 생산성을 높이기 위해 자동화 도구를 활용해야 한다. 
  - 지속적 통합을 도와주는 도구를 활용하면 개발자가 만드는 코드가 어떤 검증 절차를 자동으로 거치도록 할 수 있어서 문제를 쉽게 감지할 수 있다.


**메시지 큐, 로그, 메트릭, 자동화 등을 반영하여 수정한 설계안**  

<img width="831" alt="image" src="https://github.com/sinkyoungdeok/TIL/assets/28394879/0ebc156a-6ab2-4ccb-a255-52b55b38f090">

1. 메시지큐는 각 컴포넌트가 느슨히 결합될 수 있도록 하고, 결함에 대한 내성을 높인다.
2. 로그, 모니터링 메트릭, 자동화 등을 지원하기 위한 장치를 추가했다.


### 데이터베이스의 규모 확장  
- 저장할 데이터가 많아지면 DB에 대한 부하가 증가하고, 그때엔 DB를 증설할 방법을 찾아야 한다.
- DB 규모를 확장하는데는 수직적 규모 확장법, 수평적 규모 확장법이 있다.

**수직적 확장**  
- 고성능의 자원(CPu, RAM, 디스크 등)을 증설하는 방법
- 수직적 접근법에는 단점이 있다.
  - 무한 증설이 불가능 하다.
  - SPOF 위험성
  - 고성능 서버로 갈수록 가격이 올라가서, 비용이 많이 든다.

**수평적 확장**  
- 샤딩이라고도 부름, 더 많은 서버를 추가해서 성능 향상 
- 대규모 DB를 샤드라고 부르는 작은 단위로 분할하는 기술을 일컫는다. 
- 모든 샤드는 같은 스키마를 쓰지만 샤드에 보관되는 데이터 사이에는 중복이 없다.

<img width="834" alt="image" src="https://github.com/sinkyoungdeok/TIL/assets/28394879/71ac5974-e3c0-4203-8d4c-5f3cc64a27ed">

- 샤드로 분할된 데이터베이스의 예다.
- 이 케이스에서는 사용자 데이터를 어느 샤드에 넣을지는 사용자 ID에 따라 정한다.
- 샤딩 전략을 구현할 때 고려해야 할 가장 중요한 것은 샤딩 키를 어떻게 정하느냐다.
- 샤딩 키는 파티션 키라고도 부르는데, 데이터가 어떻게 분산될지 정하는 하나 이상의 칼럼으로 구성된다. 
- 위 케이스에서는 샤딩키가 user_id 이다. 
- 샤딩 키를 정할 때는 데이터를 고르게 분할 할 수 있도록 하는게 가장 중요하다. 


샤딩은 DB 규모 확장을 실현하는 훌륭한 기술이지만 완벽하진 않고, 도입하면 시스템이 복잡해지고 풀어야할 새로운 문제도 생긴다. 
- 데이터의 재 샤딩(resharding)
  - 1) 데이터가 너무 많아져서 하나의 샤드로는 더 이상 감당하기 어려울 때
  - 2) 샤드 간 데이터 분포가 균등하지 못하여 어떤 샤드에 할당된 공간 소모가 다른 샤드에 비해 빨리 진행될 때 
  - 샤드소진 이라고도 부르는 이런 현상이 발생하면 샤드 키를 계싼하는 함수를 변경하고 데이터를 재배치해야 한다. 안정해시 기법을 활용하면 이 문제를 해결할 수 있다.
- 유명인사(celebrity) 문제
   - 핫스팟 키 문제라고도 부르는데, 특정 샤드에 질의가 집중되어 서버에 과부하가 걸리는 문제다.
   - 이 문제를 풀려면 샤드를 잘 쪼개는게 중요하다.
- 조인과 비정규화
  - 하나의 DB를 여러 샤드 서버로 쪼개고 나면, 여러 샤드에 걸친 데이터를 조인하기가 힘들어진다. 
  - 이를 해결하는 한 가지 방법은 DB를 비정규화하여 하나의 테이블에서 질의가 수행할 수 있도록 하는 것이다. 

<img width="834" alt="image" src="https://github.com/sinkyoungdeok/TIL/assets/28394879/d259088b-afa8-4afc-9849-cfb544856613">

- 샤딩을 적용 하고 DB에 대한 부하를 줄이기 위해 굳이 RDB가 요구되지 않는 기능들은 NoSQL로 이전했다.


### 백만 사용자, 그리고 그 이상
- 시스템의 규모를 확장하는 것은 지속적이고 반복적인 과정이다. 
- 수백만 사용자 이상을 지원하려면 새로운 전략을 도입해야 하고 지속적으로 시스템을 가다듬어야 할 것이다. ex) 시스템을 최적화하고 더 작은 단위의 서비스로 분할해야 할 수도 있다. 
- 이번 장에서 시스템 규모 확장을 위해 살펴본 기법들을 정리해보면
  - 웹 계층은 무상태 계층으로
  - 모든 계층에 다중화 도입
  - 가능한 한 많은 데이터를 캐시
  - 여러 데이터 센터를 지원
  - 정적 콘텐츠는 CDN 사용 
  - 데이터 계층은 샤딩을 통해 확장
  - 각 계층은 독립적 서비스로 분할
  - 시스템을 지속적으로 모니터링하고, 자동화 도구들을 활용할 것

## 2장 개략적인 규모 추정

### 2의 제곱수

- 분산 시스템에서 다루는 데이터 양은 엄청 커질 수 있으나 계산법은 기본을 크게 벗어나지 않는다.
- 제대로 된 계산 결과를 얻으려면 데이터 볼륨의 단위를 2의 제곱수로 표현하면 어떻게 되는지 알아야 한다.

| 2의 x 제곱 | 근사치 | 이름 | 축약형 |
| --- | --- | --- | --- |
| 10 | 1천 | 1킬로바이트 | 1KB |
| 20 | 1백만 | 1메가바이트 | 1MB |
| 30 | 10억 | 1기가바이트 | 1GB |
| 40 | 1조 | 1테라바이트 | 1TB |
| 50 | 1000조 | 1페타바이트 | 1PB |

### 모든 프로그래머가 알아야 하는 응답지연 값 

- 구글의 제프 딘에서 2010년에 통상적인 컴퓨터에서 구현된 연산들의 응답지연 값을 공개했었다.
- 이들 중 몇몇은 컴퓨터가 더 빨라지면서 유효하지 않지만, 아직 어느정도 짐작할 수 있도록 해준다. 

| 연산명 | 시간 |
| --- | --- |
| L1 캐시 참조 | 0.5ns |
| 분기 예측 오류 | 5ns |
| L2 캐시 참조 | 7ns |
| 뮤텍스 락/언락 | 100ns |
| 주 메모리 참조 | 100ns |
| Zippy로 1KB 압축 | 10,000ns = 10us |
| 1 Gbps 네트워크로 2KB 전송 | 20,000ns = 20us |
| 메모리에서 1MB 순차적으로 read | 250,000ns = 250us |
| 같은 데이터 내에서의 메시지 오아복 지연시간 | 500,000ns = 500us |
| 디스크 검색 | 10,000,000ns = 10ms |
| 네트워크에서 1MB 순차적으로 read | 10,000,000ns = 10ms |
| 디스크에서 1MB 순차적으로 read | 30,000,000ns = 30ms |
| 한 패킷의 CA로부터 네덜란드까지의 왕복 지연시간 | 150,000,000ns = 150ms |

정리하자면
- 메모리는 빠르지만 디스크는 아직도 느리다
- 디스크 검색은 가능한 피하라
- 단순한 압축 알고리즘은 빠르다
- 데이터를 인터넷으로 전송하기 전에 가능하면 압축하자.
- 데이터 센터는 보통 여러 지역에 분산되어 있고, 센터들 간에 데이터를 주고받는 데는 시간이 걸린다.

### 가용성에 관계된 수치들 
- 고가용성(HA = high availability)은 시스템이 오랜 시간 동안 지속적으로 중단 없이 운영될 수 있는 능력의 용어다. 
- 100%는 시스템이 중단 없다는 의미 이고, 대부분의 서비스는 99%  ~ 100% 사이의 값을 찾는다.
- SLA(Service Level Agreement)는 서비스 사업가(service provider)가 보션적으로 사용하는 용어로, 서비스 사업자와 고객 사이에 맺어진 합의이다.
- 이 합의에는 서비스 사업자가 제공하는 서비스의 가용시간(uptime)이 공식적으로 기술되어 있다. 

| 가용률 | 하루당 장애시간 | 주당 장애시간 | 개월당 장애시간 | 연간 장애시간 |
| --- | --- | --- | ---| --- |
| 99% | 14.40분 | 1.68시간 | 7.31시간 | 3.65일 |
| 99.9% | 1.44분 | 10.08분 | 43.83분 | 8.77시간 |
| 99.99% | 8.64초 | 1.01분 | 4.38분 | 52.60분 |
| 99.999% | 864.00밀리초 | 6.05초 | 26.30초 | 5.26분 |
| 99.9999% | 86.40밀리초 | 604.80밀리초 | 2.63초 | 31.56초 |

### 예제: 트위터 QPS와 저장소 요구량 측정 

제시된 수치들은 예시일뿐, 실제 성능이나 요구사항과는 관계 없다.

가정
- 월간 능동 사용자(MAU = montly active user)는 3억명이다.
- 50%의 사용자가 트위터를 매일 사용
- 평균적으로 각 사용자는 매일 2건의 트윗을 올린다
- 미디어를 포함하는 트윗은 10% 정도다
- 데이터는 5년간 보관된다

추정
- QPS 추정치 
- 일간 능동 사용자(DAU = daily active user) = 3억 % 50% = 1.5억
- QPS = 1.5 억 X 2 트윗 / 24시간 / 3600초 = 약 3500
- 최대 QPS = 2 X QPS = 약 7000

미디어 저장을 위한 저장소 요구량 
- 평균 트윗 크기 
  - tweet_id에 64바이트
  - 텍스트에 140바이트 
  - 미디어에 1MB
- 미디어 저장소 요구량: 1.5억 X 2 X 10% X 1MB = 30TB/일
- 5년간 미디어를 보관하기 위한 저장소 요구량: 30TB X 365 X 5 = 약 55PB

### 팁

개략적 규모 추정 면접에서 가장 중요한 것은 문제를 풀어 나가는 절차고, 문제 해결 능력이다.  
- 근사치를 활용한 계산: 99987/9.1 대신 100,000 / 10으로 간소화하자.
- 가정들은 적어두자 
- 단위를 붙이자. 스스로 헷갈리지 않기 이ㅜ해
- 많이 출제되는 개략적 규모 추정 문제는 QPS, 최대 QPS, 저장소 요구량, 캐시 요구량, 서버 수 등을 추정하는 것이다. 


## 3. 시스템 설계 면접 공략법 

- 시스템 설계 면접은 두 명의 동료가 모호한 문제를 풀기 위해 협력하여 그 해결책을 찾아내는 과정에 대한 시뮬레이션이다. 
- 최종적으로 도출될 설계안은 노력에 비하면 그다지 중요하지 않다. 
- 해당 면접은 설계 기술을 시연하는 자리이고, 설계 과정에서 내린 결정들에 대한 방어 능력을 보이는 자리이며, 면접관의 피드백을 건설적인 방식으로 처리할 자질이 있음을 보이는 자리이다. 
- 많은 사람이 시스템 설계 면접은 지원자의 설계 능력의 기술적 측면을 평가하는 자리라고 생각하지만, 지원자가 협력에 적합한 사람인지, 압박이 심한 상황도 잘 헤쳐 나갈 자질이 있는지, 모호한 문제를 건설적으로 해결할 능력이 있는지, 좋은 질문을 던질 능력이 있는지 등도 평가한다. 
- 훌륭한 면접관은 부정적 신호도 놓치지 않는다.
  - 설계의 순수성에 집착한 나머지 타협적 결정(tradeoff)을 도외시하고 over-engineering을 하고 마는 엔지니어들이 현업에도 많다.
  - 그런 엔지니어들은 과도한 엔지니어링의 결과로 시스템 전반의 비용이 올라간다는 사실을 알아채지 못하는 일이 많은데, 그 결과로 상당후 회사들은 값비싼 대가를 치르고 있다. 
- 이번 장에서는 시스템 설계 면접에 관한 유용한 팁들을 살펴보고, 시스템 설계 문제를 공략하는 효과적 접근법을 소개한다.

### 효과적 면접을 위한 4단계 접근법

**1단계: 문제 이해 및 설계 범위 확정**  

- 시스템 설계 면접에서는 생각 없이 바로 답을 내서는 안된다.
- 요구사항을 완전히 이해하지 않고 답을 내놓는 행위는 엄청난 부정적 신호다.
- 속도를 늦추고, 깊이 생각하고 질문하여 요구사항과 가정들을 분명히 하자.
- 엔지니어가 가져야할 가장 중요한 기술 중 하나는 올바른 질문, 적절한 가정, 그리고 시스템 구축에 필요한 정보를 모으는 것이다.
- 요구사항을 정확히 이해하는데 필요한 질문의 예시는 
  - 구체적으로 어떤 기능들을 만들어야 하나?
  - 제품 사용자 수는 얼마나 되나?
  - 회사의 규모는 얼마나 빨리 커지리라 예상하나? 석 달, 여섯 달, 일년 뒤의 규모는 얼마가 되리라 예상하는가?
  - 회사가 주로 사용하는 기술스택은 무엇인가? 설계를 단순화하기 위해 활용할 수 있는 기존 서비스로는 어떤 것들이 있는가?


예시: 뉴스피드 시스템 설계에서 요구사항을 분명히 하기 위한 질문을 던져야 한다.

지원자: 모바일 앱과 웹 앱 가운데 어느 쪽을 지원해야 하나요? 아니면 둘 다일까요?  
면접관: 둘다 지원해야 합니다.  
지원자: 가장 중요한 기능은 무엇 인가요?  
면접관: 새로운 포스트(post)를 올리고, 다른 친구의 뉴스피드를 볼 수 있도록 하는 기능 입니다.  
지원자: 이 뉴스피드는 시간 역순으로 정렬되어야 하나요? 아니면 다른 특별한 정렬 기준이 있습니까?    
제가 특별한 정렬 기준이 있느냐고 묻는이유는, 피드에 올라갈 포스트마다 다른 가중치가 부여되어야 하는지 알고 싶어서 인데요.   
가령 가까운 친구의 포스트가 사용자그룹(user group) 에 올라가는 포스트 보다 더 중요하다거나.  
면접관: 문제를 단순하게 만들기 위해, 일단 시간 역순으로 정렬된다고 가정합시다.  
지원자: 한 사용자는 최대 몇명의 사용자와 친구를 맺을수있나요?  
면접관: 500명입니다.  
지원자: 사이트로 오는 트래픽규모는 어느정도입니까?  
면접관: 일간능동사용자(dailyactive user,DAU)는 천만명입니다.  
지원자: 피드에 이미지나 비디오도 올라올수있나요? 아니면 포스트는 그저 텍스트입니까?  
면접관: 이미지나 비디오 같은 미디어 파일도 포스트 할 수 있어야 합니다. 


**2단계: 개략적인 설계안 제시 및 동의 구하기**   
- 설계안에 대한 최초 청사진을 제시하고 의견을 구하라. 면접관을 마치 팀원인 것처럼 대하자.
- 화이트보드나 종이에 핵심 컴포넌트를 포함하는 다이어그램을 그려라. 클라이언트, API, 웹 서버, 데이터 저장소, 캐시, CDN, 메시지 큐 같은 것들이 포함될 수 있다.
- 최초 설계안이 시스템 규모에 관계된 제약사항들을 만족하는지를 개략적으로 계산해보자. 이런 개략적 추정이 필요한지는 면접관한태 미리 물어보자.

예시: 뉴스 피드 시스템을 설계에서 개략적 설계를 살펴보자   

개략적으로 보면 이 설계는 두가지 flow로 나눠 생각 할 수 있는데, 피드 발생과 피드 생성이다.
- 피드 발행: 사용자가 포스트를 올리면 관련된 데이터가 캐시/데이터베이스에 기록되고, 해당 사용자의 친구 뉴스 피드에 뜬다.
- 피드 생성: 어떤 사용자의 뉴스 피드는 해당 사용자 친구들의 포스트를 시간 역순으로 정렬하여 만든다.

![image](https://github.com/sinkyoungdeok/TIL/assets/28394879/07c15030-6ae3-4c32-ab69-46f207b40d52)  
- 3-1: 피드 발생
- 3-2: 피드 생성


**3단계: 상세 설계**     
- 이 단계로 왔다면 면접관과 다음 목표는 달성한 상태이다.  
  - 시스템에서 전반적으로 달성해야 할 목표와 기능 범위 확인
  - 전체 설계의 개략적 청사진 마련
  - 해당 청사진에 대한 면접관의 의견 청취
  - 상세 설계에서 집중해야 할 영역들 확인 
- 이제 면접관과 설계 대상 컴포넌트 사이의 우선순위를 정하는 것이다.   
- 대부분의 경우 면접관은 특정 시스템 컴포넌트들의 시부사항을 깊이 있게 설명하는 것을 보길 원한다.
- 단축 URL 생성기라면, 해시 함수의 설계를 / 채팅 시스템에 관한 문제라면, 지연시간을 줄이고 사용자의 온/오프라인 상태를 표시할 것인지를 듣고자 할 것이다.
- 반대로 불필요한 세부사항에 시간을 쓰지말자. 뉴스 피드의 순위를 매기는데 사용되는 EdgeRank 알고리즘에 대해 이야기하는 것은 바람직 하지 않다. 시간을 너무 많이 쓰고, 규묘확장 가능한 시스템 설계 능력을 보여주기에는 도움되지 않는다.


예시: 뉴스 피드 시스템의 개략적 설계를 마친 상황 (면접관도 그 설계에 만족)  

두가지 중요한 용례를 깊이 탐구하자 
1. 피드 발행 (3-3)
2. 뉴스 피드 가져오기 (3-4)

![image](https://github.com/sinkyoungdeok/TIL/assets/28394879/8313f2c3-771d-4c85-95af-8fdb153618f2)  
![image](https://github.com/sinkyoungdeok/TIL/assets/28394879/d3f41763-487e-4956-9034-1e379e1edb27)  


**4단계: 마무리**   
- 면접관이 시스템 병목구간, 혹은 좀 더 개선 가능한 지점을 찾아내라 주문할 수 있다. 
  - 설계가 완벽하다거나 개선할 부분이 없다고 답하지 말자, 개선할 점은 언제든 있다.
- 설계를 한번 다시 요약해주는 것도 좋다.
- 오류가 발생하면 무슨일이 생기는지 따져보는것도 좋다.
- 운영 이슈도 논의할 가치가 충분하다. 
  - 메트릭은 어떻게 수집하고 모니터링?
  - 로그는?
  - 시스템은 어떻게 배포(roll-out)해나 갈 것인가?
- 미래에 닥칠 규모 확장 요구에 어떻게 대처할 것인지도 좋다.
- 시간이 좀 남으면, 필요하지만 다루지 못했던 세부적 개선사항들을 제안해보자.



면접 세션에서 해야 할 것  
- 질문을 통해 확인하자. 스스로 내린 가정이 옳다 믿고 진행하지 말자
- 문제의 요구사항을 이해해라
- 정답이나 최선의 답안 같은 것은 없다는 것을 명심하자
- 사고 흐름을 이해할 수 있도록 소통 하자
- 가능하다면 여러 해법을 함께 제시하자
- 개략적 설계에 면접관이 동의하면, 각 컴포넌트의 세부사항을 설명하기 시작하고 가장 중요한 컴포넌트부터 진행해라.
- 면접관의 아이디어를 이끌어 내자. 좋은 면접관은 팀원처럼 협력한다
- 포기하지 말자

면접 세션에서 하면 안되는 것  
- 전형적인 면접 문제들에도 대비하지 않은 상태에서 면접장에 가지 말자
- 요구사항이나 가정들을 분명히 하지 않은 상태에서 설계를 제시하지 말자
- 처음부터 특정 컴포넌트의 세부사항을 깊이 설명하지 말자. 개략적 부터 세부사항으로 가자.
- 진행 중에 막혔다면, 힌트를 청하자
- 침묵 속의 설계를 진행하지 말자.
- 설계안을 내놓는 순간 면접이 끝났다고 생각하지 말자. 의견을 일찍, 자주 구하자

시간 배분 - 예시 45분 
1. 문제 이해 및 설계 범위 확정: 3분 ~ 10분
2. 개략적 설계안 제시 및 동의 구하기: 10분 ~ 15분
3. 상세 설계: 10분 ~ 25분
4. 마무리: 3분 ~ 5분 


## 4. 처리율 제한 장치의 설계 

- 네트워크 시스템에서 rate limiter(처리율 제한 장치)는 클라이언트 또는 서비스가 보내는 트래픽의 처리율을 제어하기 위한 장치이다.
- HTTP에선 클라이언트의 요청 횟수를 제한한다.
- API 요청 횟수가 제한 장치에 정의된 threshold를 넘어서면 추가로 도달한 모든 호출은 처리가 중단된다. 
- 예시
  - 사용자는 초당 2회 이상 새 글을 올릴 수 없다.
  - 같은 IP 주소로는 하루에 10개 이상의 계정을 생성할 수 없다.
  - 같은 디바이르소는 주당 5외 이상 리워드를 요청할 수 없다.

API에 rate limiter를 적용하면 좋은점
- DOS 공격에 의한 자원 고갈(resource starvation) 방지 
  - 예) 트위터는 3시간동안 300개의 트윗만 올릴 수 있도록 제한하고 있다.
- 비용을 절감한다
  - 서버를 많이 두지 않아도 되고, 우선순위가 높은 API에 더 많은 자원을 할당할 수 있음.
  - 신용을 확인하거나, 신용카드 결제를 하거나, 건강 상태를 확인하거나 하기 위해 호출하는 API에 대한 과금이 횟수에 따라 이뤄져야 비용 절감이 가능하다.
- 서버 과부하를 막는다.
  - 봇에서 오는 트래픽이나 사용자의 잘못된 이용패턴으로 유발된 트래픽을 걸러낼 수 있다.



### 1단계: 문제 이해 및 설계 범위 확정

rate limiter를 구현할 때 여러 가지 알고리즘을 사용할 수 있는데, 각각은 고유한 장단점을 갖고 있다.

**요구사항**  
- 설정된 처리율을 초과하는 요청은 정확하게 제한한다.
- 낮은 응답시간: rate limiter는 HTTP 응답시간에 나쁜 영향을 주면 안된다.
- 가능한 한 적은 메모리를 써야 한다.
- distributed rate limiting: 하나의 rate limiter를 여러 서버나 프로세스에서 공유할 수 있어야 한다.
- 예외 처리: 요청이 제한되었을 때는 그 사실을 사용자에게 분명하게 보여주어야 한다.
- 높은 결함 감내성(fault tolerance): 제한 장치에 장애가 생기더라도 전체 시스템에 영향을 주면 안된다.

### 2단계: 개략적 설계안 제시 및 동의 구하기

일을 너무 복잡하게 만드는 것은 피하고, 기본적인 클라이언트-서버 통신 모델을 사용하자.

**rate limiter는 어디에 둘 것인가?**  
- 클라이언트에 둔다면: 일반적으로 클라이언트는 rate limiter를 안정적으로 걸 수 있지 않다. 클라이언트 요청은 쉽게 위변조가 가능하기 떄문이고, 모든 클라이언트의 구현을 통제하는 것도 어려울 수 있다.

**서버 1안**

![image](https://github.com/sinkyoungdeok/TIL/assets/28394879/1bd4da30-0543-4e55-84e4-8d8c357cefaf)



**서버 2안**   

![image](https://github.com/sinkyoungdeok/TIL/assets/28394879/bda941ce-5727-42e7-88fc-13bc69fcc154)  
- 처리율 제한 장치를 API 서버에 두는 대신, 처리율 제한 미들웨어를 만들어 미들웨어를 통해 API 서버로 가는 요청을 통제한다.
- 클라우드 마이크로서비스의 경우, rate limiter는 보통 API 게이트웨이라 불리는 컴포넌트에 구현된다.
- 클라우드 업체가 처리율 제한, SSL 종단, 사용자 인증, IP 허용목록 관리 등을 지원하는 완전 위탁관리형 서비스를 API게이트웨이에서 만들고 유지보수한다.
- rate limiter 기능을 설계할 때 중요하게 따져야 하는것은
  - 서버에 둘지, 게이트웨이에 둘지다.
  - 회사의 기술 스택, 엔지니어링 인력, 우선순위, 목표에 따라 달라질 수 있다.


rate limiter에 일반적으로 적용될 수 있는 몇가지 지침   
- 프로그래밍 언어, 캐시 서비스 등 현재 사용하고 있는 기술 스택을 점검. 현재 사용하는 프로그래밍 언어가 서버 측 구현을 지원하기 충분할 정도로 효율이 높은지 확인하자.
- 필요에 맞는 처리율 제한 알고리즘을 찾자. 서버측에서 구현하면, 알고리즘은 자유롭게 선택할 수 있지만, 제3 사업자가 제공하는 게이트웨이를 사용하면 선택지는 제한될 수 있다.
- 설계가 마이르코서비스에 기반하고 있고, 사용자 인증이나 IP 허용목록 관리 등을 처리하기 위해 API 게이트웨이를 이미 설계에 포함시켰다면 rate limiter도 포함시키는게 좋다.
- rate limiter를 만드는 데도 시간이 많이 든다. 구현하기에 충분한 인력이 없다면 상용 API 게이트웨이를 쓰는 것이 바람직하다.


**처리율 제한 알고리즘**  
널리 알려진 알고리즘  
- 토큰 버킷
- 누출 버킷
- 고정 윈도 카운터
- 이동 윈도 로그
- 이동 윈도 카운터 

**1. 토큰 버킷 알고리즘**  
- rate limiter에 폭넓게 이용되고 있다.
- 간단하고, 알고리즘에 대한 세간의 이해도도 높은 편이며 인터넷 기업들이 보편적으로 사용하고 있다.
- 아마존, 스트라라이프가 사용중이다.

토큿 버킷 알고리즘의 동작 원리    
![image](https://github.com/sinkyoungdeok/TIL/assets/28394879/ebd13289-58bd-4863-9dd9-988550decdb1)     
- 토큰 버킷은 지정된 용량을 갖는 컨테이너다.
- 이 버켓에 사전 설정된 양의 토큰이 주기적으로 채워진다.
- 토큰이 꽉 찬 버킷에는 더 이상의 토큰은 추가되지 않는다.
- 위 그림 예제는 용량이 4인 버킷.
- 토큰 공급기(refiller)는 이 버킷에 매초 2개의 토큰을 추가하고, 버킷이 가득 차면 추가로 공급된 토큰은 버려진다.
- 각 요청은 처리될 때마다 하나의 토큰을 사용하는데, 요청이 도착하면 버킷에 충분한 토큰이 있는지 검사한다.
  - 충분한 토큰이 있는 경우, 버킷에서 토큰 하나를 꺼낸 후 요청을 시스템에 전달한다.
  - 충분한 토큰이 없는 경우, 해당 요청은 버려진다.

![image](https://github.com/sinkyoungdeok/TIL/assets/28394879/6ed112c9-da5f-4f84-9c11-351ad187ba23)  
- 토큰 버킷 크기:4 , 토큰 공급률: 분당 4
- 토큰 버킷 알고리즘은 2개 인자를 받는다
  - 버킷 크기: 버킷에 담을 수 있는 토큰 최대 갯수
  - 토큰 공급률: 초당 공급되는 버킷 수 


버킷은 몇개나 사용해야 할까? 공급 제한 규칙에 따라 달라진다.  
- 통상적으로, API 엔드포인트마다 별도의 버킷을 둔다. 예) 사용자마다 하루에 한 번만 포스팅 할 수 있음
- IP 주소별로 처리율 제한을 적용해야 한다면, IP 주소마다 버킷을 하나씩 할당해야 한다.
- 시스템의 처리율을 초당 10,000개 요청으로 제한하고 싶다면, 모든 요청이 하나의 버킷을 공유하도록 해야 할 것이다.


토큰 버킷 알고리즘의 장단점  

장점
- 구현이 쉬움
- 메모리 사용 측면에서도 효율
- 짧은 시간에 집중되는 트래픽도 처리 가능. 
- 버킷에 남은 토큰이 있기만 하면 요청은 시스템에 전달된다.  

단점
- 파라미터 2개 (버킷 크기, 공급률) 값을 적절하게 튜닝하는 것이 까다롭다


**2. 누출 버킷 알고리즘**  

- 토큰 버킷 알고리즘과 비슷하지만 요청 처리율이 고정되어 있다는 점이 다르다.
- 보통 FIFO 큐로 구현한다.


동작 원리

![image](https://github.com/sinkyoungdeok/TIL/assets/28394879/bbd11ec1-d808-4384-bbbc-b06a781c0b22)  
- 요청이 도착하면 큐가 가득 차 있는지 보고, 빈자리가 있는 경우에는 큐에 요청을 추가한다
- 큐가 가득 차 있는 경우에는 새 요청은 버린다.
- 지정된 시간마다 큐에서 요청을 꺼내어 처리한다.
- 인자는 두개를 사용한다
  - 버킷 크기: 큐 사이즈.
  - 처리율: 지정된 시간당 몇 개의 항목을 처리할지 지정하는 값. 보통 초 단위로 표현
- 전자상 거래 기업인 쇼피파이가 사용중.

장점  
- 큐의 크기가 제한되어 있어 메모리 사용량 측면에서 효율적 
- 고정된 처리율을 갖고 있기 때문에 안정적 출력이 필요한 경우에 적합하다.

단점  
- 단시간에 많은 트래픽이 몰리는 경우 큐에는 오래된 요청들이 쌓이게 되고, 그 요청들을 제때 처리 못하면 최신 요청들은 버려진다.
- 두개의 파라미터를 올바르게 튜닝하기가 까다롭다.


**3. 고정 윈도 카운터 알고리즘**  

동작 원리  

- 타임라인을 고정된 간격의 윈도로 나누고, 각 윈도마다 카운터를 붙인다.
- 요청이 접수될 때마다 이 카운터의 값은 1씩 증가한다
- 이 카운터의 값이 사전에 설정된 threshold에 도달하면 새로운 요청은 새 윈도가 열릴 때까지 버려진다

장점  
- 메모리 효율 좋고, 이해하기 쉬움
- 윈도가 닫히는 시점에 카운터를 초기화하는 방식은 특정한 트래픽 패턴을 처리하기에 적합하다

단점  
- 윈도 경계 부근에서 일시적으로 많은 트래픽이 몰려드는 경우, 기대했던 시스템의 처리 한도보다 많은 양의 요청을 처리하게 된다.



**4. 이동 윈도 로깅 알고리즘**  
- 고정 윈도 카운터 알고리즘의 윈도 경계 부근에 트래픽이 집중되는 경우 시스템에 설정된 한도보다 많은 요청을 처리하는 현상을 해결할 수 있다.

동작 원리  
- 요청의 타임스탬프를 추적한다. 타임스탬프 데이터는 보통 redis의 정렬 집합(sorted set) 같은 캐시에 보관한다.
- 새 요청이 오면 만료된 타임스탬프는 제거한다. 만료된 타임스탬프는 그 값이 현재 윈도의 시작 시점보다 오래된 타임스탬프를 말한다.
- 새 요청의 타임스탬프를 로그에 추가한다.
- 로그의 크기가 허용치보다 같거나 작으면 요청을 시스템에 전달한다. 그렇지 않은 경우에는 처리를 거부한다.


예) 분당 2개 요청이 한도인 시스템  
- 요청이 1:00:01에 도착할 때, 로그가 비어있으므로 허용
- 요청이 1:00:30에 도착할 때, 허용 한도인 2보다 크지 않으므로 허용
- 요청이 1:00:50에 도착할 때, 추가 직후 로그 크기는 3이므로, 거부되지만 타임스탬프는 추가한다
- 요청이 1:01:40에 도착할 때, [1:00:40, 1:01:40) 범위 안에 있는 요청이 1분 윈도 안에 요청이고, 그 이전 타임스탬프는 만료된 값이다. 그래서 만료된 타임스탬프인 01, 30초 로그를 지우고 해당 요청은 허용한다.

장점  
- 알고리즘 메커니즘이 아주 정교하다. 
- 어느순간의 윈도를 보더라도, 허용되는 요청의 개수는 시스템의 처리율 한도를 넘지 않는다.

단점  
- 다량의 메모리를 사용한다.
- 거부된 요청의 타임스탬프도 보관하기 때문이다. 

**5. 이동 윈도 카운터 알고리즘**     
- 고정 윈도 카운터 알고리즘 + 이동 윈도 로깅 알고리즘
- 구현방법은 2가지인데, 여기서는 하나만 설명 


동작 원리  
- 처리율 제한 장치의 한도: 분당 7개, 이전 1분 동안 5개 요청, 현재 1분 동안 3개의 요청이 왔다고 해보자.
- 현재 1분의 30% 시점에 도착한 새 요청의 경우, 현재 윈도에 몇 개의 요청이 온것으로 보고 처리할까?
  - 현재 1분간의 요청 수 + 직전 1분간의 요청 수 X 이동 윈도와 직전 1분이 겹치는 비율 
  - 3 + 5 X 70% = 6.5개. 반올림, 내림 둘다 쓸 수 있지만, 여기에서는 내림하여 써서 6이다.
- 분당 한도가 7개 요청이므로 이번 요청은 성공하지만, 그 직후에는 요청을 받을 수 없게 된다.

장점  
- 이전 시간대의 평균 처리율에 따라 현재 윈도의 상태를 계산하므로 짧은 시간에 몰리는 트래픽에도 잘 대응한다.
- 메모리 효율이 좋다.

단점  
- 직접 시간대에 도착한 요청이 균등하게 분포되어 있다고 가정한 상태에서 추정치를 계산하기 때문에 다소 느슨하다.
- 하지만 이 문제는 생각만큼 심각하진 않지만, 클라우드 플레어가 실시했던 실험에 따르면 40억 개의 요청 가운데 시스템의 실제 상태와 맞지 않게 허용되거나 버려진 요청은 0.003%에 불과했다. 


**개략적인 아키텍처**  
- rate limiter 알고리즘의 기본 아이디어는 단순하다.
- 얼마나 많은 요청이 접수되었는지를 추적할 수 있는 카운터를 추적 대상 별로 두고 (사용자, IP, API 엔드포인트, 서비스 단위 등), 이 카운터의 값이 한도를 넘으면 이후 도착한 요청은 거부한다.
- 그럼 카운터는 어디 보관 할까?
  - DB는 느려서 안되고
  - 메모리상에서 동작하는 캐시가 바람직한데, 빠른데다 시간에 기반한 만료 정책을 지원하기 때문이다. 
  - 레디스는 rate limiter를 구현할 때 자주 사용되는 메모리 기반 저장장치로서, INCR와 EXPIRE 두가지 명령어를 지원한다.
    - INCR: 메모리에 저장된 카운터의 값을 1만큼 증가
    - EXPIRE: 카운터에 타임아웃 값을 설정하고, 설정된 시간이 지나면 카운터는 자동으로 삭제된다.

![image](https://github.com/sinkyoungdeok/TIL/assets/28394879/3e6b32ef-ecc3-4d2f-b600-7a6225284e39)  
- 클라이언트가 처리율 제한 미들웨엉에게 요청을 보낸다.  
- 처리율 제한 미들웨어는 레시드의 지정 버킷에서 카운터를 가져와서 한도에 도달했는지 아닌지를 검사한다 
  - 한도에 도달하면 요청은 거부
  - 도달하지 않았다면 요청은 API 서버로 전달하고 미들웨어는 카운터의 값을 증가시킨 후 다시 레디스에 저장한다.


### 3단계: 상세 설계   
4-12 그림에서는 다음과 같은 사항은 알 수 없었다.  
- 처리율 제한 규칙은 어떻게 만들어지고 어디에 저장하나?
- 처리가 제한된 요청들은 어떻게 처리되는가?  

**처리율 제한 규칙**  
```yaml
domain: messaging
descriptors:
  - key: message_type
    Value: marketing
    rate_limit:
      unit: day
      requests_per_unit: 5
```
- 마케팅 메시지의 최대치를 하루 5개로 제한한 예제

```yaml
domain: auth
descriptors:
  - key: auth_type
    Value: login
    rate_limit:
      unit: minute
      requests_per_unit: 5
```
- 분당 5회 이상 로그인 할 수 없도록 제한한 예제 
- 이런 규칙들은 보통 설정파일 형태로 디스크에 저장된다.

**처리율 한도 초과 트래픽의 처리**  
- 어떤 요청이 한도 제한에 걸리면 HTTP 429 응답을 클라이언트에 보낸다.  
- 경우에 따라서는 한도 제한에 걸린 메시지를 나중에 처리하기 위해 큐에 보관할 수도 있다.
- 예를 들어, 어떤 주문이 시스템 과부하 때문에 한도 제한에 걸렸다고 하면 해당 주문건들은 보관했다가 나중에 처리할 수도 있을 것 이다.

처리율 제한 장치가 사용하는 HTTP 헤더  
- 클라이언트는 자기 요청이 처리율 제한에 걸리고 있는지를(throttle) 어떻게 감지할 수 있나?  
- 자기 요청이 처리율 제한에 걸리기까지 얼마나 많은 요청을 보낼 수 있는지 어떻게 알 수 있나?
- 답은 HTTP 응답 헤더에 있다.
- 이번 장에서 설계하는 rate limiter 헤더
  - X-Ratelimit-Remaining: 윈도 내에 남은 처리 가능 요청의 수
  - X-Ratelimit-Limit: 매 윈도마다 클라이언트가 전송할 수 있는 요청의 수
  - X-Ratelimit-Retry-After: 한도 제한에 걸리지 않으려면 몇 초 뒤에 요청을 다시 보내야 하는지 알림 
- 사용자가 너무 많은 요청을 보내면 429 오류를 X-Ratelimit-Retry-After 헤더와 함께 반환한다.


**상세 설계**  
![image](https://github.com/sinkyoungdeok/TIL/assets/28394879/210383ad-d361-4925-b39c-db6c11c806a1)   
- 처리율 제한 규칙은 디스크에 보관하고, 작업 프로세스(workers)는 수시로 규칙을 디스크에서 읽어 캐시에 저장한다
- 클라이언트가 요청을 서버에 보내면 처리율 제한 미들웨어에 도달한다.
- 처리율 제한 미들웨어는 제한 규칙을 캐시에서 가져온다. 아울러 카운터 및 마지막 요청의 타임스탬프를 레디스 캐시에서 가져온다. 
  - 요청이 제한에 걸리지 않으면 API 서버로 보낸다
  - 제한에 걸리면 429 에러를 클라이언트에 보낸다. 한편 해당 요청은 그대로 버릴 수도 있고 메시지 큐에 보관할 수도 있다.


**분산 환경에서의 처리율 제한 장치의 구현**  
- 단일 서버에서의 rate limiter는 어렵지 않다.
- 하지만 여러 대의 서버와 병렬 스레드를 지원하도록 시스템을 확장하는 것은 또 다른 문제다. 다음 두가지 어려운 문제를 풀어야 한다
  - 경쟁 조건 
  - 동기화


경쟁 조건  
rate limiter는 다음으로 동작한다  
- 레디스에서 카운터의 값을 읽는다
- counter + 1 값이 임계치를 넘는지 본다
- 넘지 않는다면 레디스에 보관된 카운터 값을 1만큼 증가시킨다.

![image](https://github.com/sinkyoungdeok/TIL/assets/28394879/147afc24-89af-4e40-9f1a-2dceef0c40b9)  
- 병행성이 심한 환경에서는 위와 같은 경쟁 조건 이슈가 발생할 수 있다.  
- 레디스에 저장된 변수 counter의 값이 3이라고 하자.
- 그리고 두 개 요청을 처리하는 스레드가 각각 병렬로 counter 값을 읽었지만 변경된 값을 저장하지 않은 상태이다.
- 둘다 다른 요청의 처리 상태는 상관하지 않고 counter에 1을 더한 값을 레디스에 기록할 것이다.
- 4로 변경될거지만, 사실은 5가 되어야 한다.
- 경쟁 조건 문제를 해결하는 가장 널리 알려진 해결책은 락이다.
- 하지만 락은 시스템의 성능을 상당히 떨어뜨리는 문제가 있다.  
- 위 설계의 경우에는 락 대신 쓸 수 있는 해결책이 두 가지 있는데, 하나는 루아 스크립트이고 다른 하나는 정렬 집합이라 불리는 레디스 자료구조를 쓰는 것이다.


동기화 이슈  
- 동기화는 분산 환경에서 고려해야 할 또 다른 중요한 요소다.
- 수백만 사용자를 지원하려면 한 대의 rate limiter 서버로는 충분하지 않을 수 있다.
- 그래서 rate limiter 서버를 여러 대 두게 되면 동기화가 필요해진다.  

![image](https://github.com/sinkyoungdeok/TIL/assets/28394879/e4b7a8bb-2c41-4a73-b604-4b7480e2646f)  
- 왼쪽 그림: 클라이언트 1은 rate limit1, 클라이언트 2는 rate limit
- 웹 계층은 stateless이므로 다음 요청은 우측 그림처럼 보낼 수 있다.
- 이때 동기화를 하지 않는다면 제한 장치 1은 클라이언트 2에 대해서는 아무것도 몰라서 처리율 제한을 올바르게 수행할 수 없을 것이다. 
- 고정 세션을 활용해서 해결할 수도 있는데, 확장 가능하지도 않고 유연하지도 않아서 좋지 않다.  


![image](https://github.com/sinkyoungdeok/TIL/assets/28394879/f1d0625e-8add-4fcb-a8af-0b1c4cc9ab1a)  
- 더 나은 해결책은 레디스와 같은 중앙 집중형 데이터 저장소를 쓰는 것이다.   


성능 최적화  
- 성능 최적화는 시스템 설계 면접의 단골 주제다.   
- 지금까지 살펴본 설계는 두가지 지점에서 개선 가능하다.  
- 우선, 여러 데이터센터를 지원하는 문제는 처리율 제한 장치에 매우 중요한 문제다. 데이터센터에서 멀리 떨어진 사용자를 지원하려다보면 latency가 증가할수 밖에 없기 때문이다.
  - 대부분의 클라우드 사업자는 세계 곳곳에 edge server를 심어놓고, 사용자 트래픽을 가장 가까운 edge server로 전달하여 지연시간을 줄인다.
- 두번째로 고려할 것은 rate limit 장치 간에 데이터를 동기화 할 때 최종 일관성 모델을 사용하는 것이다.


모니터링  
처리율 제한 장치를 설치한 이후에는 효과적으로 동작하고 있는지 보기 위해 데이터를 모아야한다. 기본적으로 모니터링을 통해 확인하는것은 다음과 같다
- 채택된 처리율 제한 알고리즘이 효과적이다.
- 정의한 처리율 제한 규칙이 효과적이다.

예를 들어 처리율 제한 규칙이 너무 빡빡하면 많은 유효 요청이 처리되지 못하고 버려질 것이다. 그런 일이 벌어진다면 규칙을 완화할 필요가 있다.  
깜짝 세일 같은 이벤트 때문에 트래픽이 급증할 때 처리율 제한 장치가 비효율적으로 동작하면, 그런 트래픽 패턴을 잘 처리할 수 있도록 알고리즘을 바꾸는것을 생각해보자.  
그런 상황에서는 토큰 버킷이 적합할 것이다.  

### 4단계: 마무리  
시스템 설계 문제와 마찬가지로, 시간이 허락한다면 다음과 같은 부분을 언급해보면 도움 될 것이다.  
- 경성(hard) 또는 연성(soft) 처리율 제한  
  - 경성 처리율 제한: 요청의 개수는 임계치를 절대 넘어설 수 없다.
  - 연성 처리율 제한: 요청 개수는 잠시 동안은 임계치를 넘어설 수 있다.
- 다양한 계층에서의 처리율 제한
  - 이번 장에서는 애플리케이션 계층에서의 처리율 제한에 대해서만 알아보았다.
  - 하지만, 다른 계층에서도 처리율 제한이 가능하다.
  - 예를 들어, Iptables를 사용하면 IP 주소(IP는 OSI 기준으로 3번 계층인 네트워크 계층)에 처리율 제한을 적용하는 것이 가능하다.
- 처리율 제한을 회피하는 방법. 클라이언트를 어떻게 설계하는 것이 최선인가?  
  - 클라이언트 측 캐시를 사용하여 API 호출 횟수를 줄인다.
  - 처리율 제한의 임계치를 이해하고, 짧은 시간 동안 너무 많은 메시지를 보내지 않도록 한다.
  - 예외나 에러를 처리하는 코드를 도입하여 클라이언트가 예외적 상황으로부터 gracefully(우아하게) 복구될 수 있도록 한다.
  - 재시도(retry) 로직을 구현할 때는 충분한 백오프(back-off) 시간을 둔다.

## 5. 안정 해시 설계 

- 슈평적 규모 확장성을 달성하기 위해서는 요청 또는 데이터를 서버에 균등하게 나누는 것이 중요하다.
- 안정 해시는 이 목표를 달성하기 위해 보편적으로 사용하는 기술이다.

### 해시 키 재배치 문제  

- N개의 캐시 서버들에 부하를 균등하게 나누는 보편적 방법은 아래의 해시 함수를 사용하는 것이다. 
  - `serverIndex=hash(key) % N 
- server pool의 크기가 고정되어 있을 때, 그리고 데이터 분포가 균등할 때는 잘 동작한다.
- 하지만 서버가 추가되거나 기존 서버가 삭제되면 문제가 생긴다. (서버가 중단되어서 서버풀의 크기를 1개를 줄이면 서버 인덱스가 변한다.)
- 장애가 발생한 서버에 보관되어 있는 키 뿐만 아니라 대부분의 키가 재분배되고 그 결과 대규모 캐시 미스가 발생하게 된다.
- 안정 해시는 이 문제를 효과적으로 해결하는 기술이다.

### 안정 해시  
- 안정해시: 해시 테이블 크기가 조정될 때 평균적으로 k/n개의 키만 재배치하는 해시 기술 (k = 키의 개수, n 슬롯 개수)
- 대부분의 전통 해시 테이블: 슬롯의 수가 바뀌면 거의 대부분 키를 재배치한다. 

**해시 공간과 해시 링**  
![image](https://github.com/sinkyoungdeok/TIL/assets/28394879/7b2badc9-d9ea-4b48-8505-d02a859a09c9)  
- 해시 함수 f로 SHA-1을 사용한다고 하고
- SHA-1 해시 공간 범위는 0 ~ 2^160 - 1 이므로 x0 ~ xn 값은 해당 범위이다.
- 해시 공간의 양쪽을 구부려 접으면 해시 링이 만들어진다. 


**해시 서버**  
![image](https://github.com/sinkyoungdeok/TIL/assets/28394879/2922f162-dabe-438d-88f9-80036f6c55a1)  
- 이 해시 함수 f를 사용하면 서ㅓㅂ IP나 이름을 이 링 위에 대응시킬 수 있다. 
- 위 그림은 4개의 서버를 해시 링 위에 배치한 결과다.

**해시 키**  
![image](https://github.com/sinkyoungdeok/TIL/assets/28394879/96d5cebc-bd30-4c1e-9bec-e952d7d34c98)  
- 아까 위의 "해시 키 재배치 문제" 에 언급된 함수와는 다른 함수다 (% 연산으로 하는게 아님)
- 위 그림은 캐시할 키 key0 ~ key3 도 해시 링에 배치한 결과이다.

**서버 조회**  
![image](https://github.com/sinkyoungdeok/TIL/assets/28394879/0711478e-97a2-4a07-9de0-1a3d93c79221)  
- 어떤 키가 저장되는 서버는, 해당 키의 위치로부터 시계 방향으로 링을 탐색 해나가면서 만나는 첫번째 서버다.

**서버 추가**  
![image](https://github.com/sinkyoungdeok/TIL/assets/28394879/91090716-34ca-4dd3-b521-a5572a4ed43c)  
- 서버를 추가하더라도 키 가운데 일부만 재배치하면 된다.  
- 위 그림은 서버 4가 추가된 뒤에 key0만 재배치됐다.

**서버 제거**  
![image](https://github.com/sinkyoungdeok/TIL/assets/28394879/cc84117d-4fe7-49aa-9cf6-ef3285db1395)  
- 하나의 서ㅓㅂ가 제거되면 키 가운데 일부만 재배치된다.
- 위 그림은 서버 1이 삭제되었을 때 key1만 서버2로 재배치된 것을 보여준다. 

**기본 구현법의 두 가지 문제**  
- 안정 해시 알고리즘의 기본 절차는 다음과 같다.
  - 서버와 키를 균등 분포 해시 함수를 사용해 해시 링에 배치한다.
  - 키의 위치에서 링을 시계빵향으로 탐색하다 만나는 최초의 서버가 키가 저장될 서버다. 

![image](https://github.com/sinkyoungdeok/TIL/assets/28394879/f8f85990-9d67-4e67-9ced-8706f5b9edb0)  
- 이 접근법에는 두가지 문제가 있다. 
- 1) 서버가 추가되거나 삭제되는 상황을 감안하면 파티션의 크기를 균등하게 유지하는 게 불가능하다. (파티션 == 인접한 서버 사이의 해시 공간) 어떤 서버는 굉장히 작은 해시 공간, 어떤 서버는 굉장히  큰 해시 공간을 할당 받는다. 
- 위 그림은 s1이 삭제되는 바람에 s2의 파티션이 다른 파티션 대비 거의 두 배로 커지는 상황을 보여준다.

![image](https://github.com/sinkyoungdeok/TIL/assets/28394879/0681d2f3-b365-4751-b566-f9dfd4f8fe6b)  
- 2) 키의 균등 분포를 달성하기가 어렵다. 
- 위 그림은 서버1과 서버3은 아무 데이터도 갖지 않는 반면, 대부분의 키는 서버2에 보관될 것이다. 
- 이 문제를 해결하기 위해 제안된 기법이 가상노드 또는 복제라 불리는 기법이다.


**가상 노드**  
![image](https://github.com/sinkyoungdeok/TIL/assets/28394879/a8e9991b-0397-425a-a174-49a08010fb10)  
- 가상 노드는 실제 노드 또는 서버를 가리키는 노드로서, 하나의 서버는 링 위에 여러개의 가상 노드를 가질 수 있다.
- 위 그림을 보면 서버0와 서버1은 3개의 가상 노드를 갖는다. (숫자 3은 임의의 숫자로 정한 것, 실제 시스템에서는 훨씬 큰값을 사용한다)
- 서버 0을 링에 배치하기 위해 s0 하나만 쓰는 대신, s0_0, s0_1, s0_2의 세 개 가상 노드를 사용한다. (서버 1도 마찬가지)
- 각 서버는 여러개의 파티션을 관리해야 한다.   

![image](https://github.com/sinkyoungdeok/TIL/assets/28394879/ddd4f3bc-2cb9-4fb9-9825-a7c8030d11da)  
- 키의 위치로부터 시계방향으로 링을 탐색하다 만나는 최초의 가상 노드가 해당 키가 저장될 서버가 된다.  
- k0가 저장되는 서버는 k0의 위치로부터 링을 시계방향으로 탐색하다 만나는 최초의 가상 노드 s1_1 (서버1)이다.
- 가상 노드의 개수를 늘릴수록 키의 분포는 점점 더 균등해진다.
- 표준 편차가 작아져서 데이터가 고르게 분포되기 떄문이다. (표준 편차 == 데이턱 어떻게 퍼져 나갔는지를 보이는 척도)
- 100~200개의 가상 노드 => 표준 편차 평균 10% ~ 5%
- 가상 노드를 늘릴수록 표준 편차의 값은 떨어지지만, 반대로 가상 노드 데이터를 저장할 공간은 더 많이 필요하다 (trade off)
- 시스템 요구사항에 맞도록 가상 노드 개수를 적절히 조정해야 한다.

**재배치할 키 결정**  
![image](https://github.com/sinkyoungdeok/TIL/assets/28394879/1dc97586-c8dd-42ef-bcdd-9153f93a568b)  
- 서버가 추가되거나 제거되면 데이터 일부는 재배치해야한다. 어느 범위의 키들이 재배치되어야 할까?
- 위의 그림은 서버4가 추가되고, s4부터 그 반시계 방향에 있는 첫번째 서버 s3까지 영향을 받았다.
- 즉 s3부터 s4사이에 있는 키들을 s4로 재배치해야한다. 

![image](https://github.com/sinkyoungdeok/TIL/assets/28394879/d2a44618-a1b0-43ac-9e00-4ecbcd4bb35a)  
- 서버 s1이 삭제되면 s1부터 그 반시계 방향에 있는 최초 서버 s0 사이에 있는 키들이 s2로 재배치되어야한다.  

### 마치며  
안정 해시의 이점
- 서버가 추가되거나 삭제될 대 재배치되는 키의 수가 최소화 
- 데이터가 균등하게 분포하게 되므로 수평적 규모 확장성을 달성하기 쉽다
- 핫스팟 키 문제를 줄인다. 
  - 특정한 샤드에 대한 접근이 지나치게 빈번하면 서버 과부하 문제가 생길 수 있다.
  - 케이티 페리, 저스틴 비버, 레이디 가가 같은 유명인의 데이터가 전부 같은 샤드에 몰리는 상황이 이러한 것이다.
  - 안정 해시는 데이터를 좀 더 균등하게 분배하므로 위의 문제가 생길 가능성을 줄인다.
- 안정 해시 사용 예시
  - 아마존 다이나모 DB의 파티셔닝 관련 컴포넌트
  - 아파치 카산드라 클러스터에서의 데이터 파티셔닝
  - 디스코드 채팅 어플리케이션
  - 아카마이 CDN
  - 매그레프 네트워크 부하 분산기 


## 6. 키-값 저장소 설계
key-value store는 key-value db라고도 불리는 non-relational db이다.  
저장소에 저장되는 값은 고유 식별자를 키로 가져야 한다.  
키와 값 사이의 이런 연결 관계를 "키-값" 쌍이라고 지칭한다.

키  
- 값은 키를 통해서만 접근할 수 있다.  
- 키는 일반 텍스트일 수도 있고, 해시 값일 수도 있다.  
- 성능상 키는 짧을수록 좋다.

값  
- 값은 문자열, 리스트, 객체 등이 될 수 있고 무엇이든 될 수 있다.

key-value DB예시로는 ex) 아마존 다이나모, memcached, 레디스 


### 문제 이해 및 설계 범위 확정  
- 완벽한 설계란 없다.  
- 읽기, 쓰기 그리고 메모리 사용량 사이에 어떤 균형을 찾고, 데이터의 일관성과 가용성 사이에서 타협적 결정을 내린 설계를 만드는게 좋다.  
- 이번장에서는 다음 특성을 갖는 key-value store를 설계해보자. 
  - 키-값 쌍의 크기는 10KB 이하
  - 큰 데이터를 저장할 수 있어야 한다.
  - 높은 가용성을 제공해야 함. 따라서 시스템은 장애가 있더라도 빨리 응답해야 한다.
  - 높은 규모 확장성을 제공해야 함. 따라서 트래픽 양에 따라 자동으로 서버 증설/삭제가 이루어져야 한다
  - 데이터 일관성 수준은 조정이 가능해야 한다
  - 응답 지연시간(latency)이 짧아야 한다.

### 단일 서버 키-값 저장소   
- 한 대 서버만 사용하는 키-값 저장소를 설계하는 것은 쉽다.  
- 가장 직관적인 방법은 키-값 쌍 전부를 메모리에 해시 테이블로 저장하는 것
- 그러나 빠른속도를 보장하지만, 모든 데이터를 메모리 안에 두는 것이 불가능 할 수 있다는 약점이 있다. 
- 이 문제를 해결하기 위한 개선책은 
  - 데이터 압축
  - 자주 쓰이는 데이터만 메모리에 두고 나머지는 디스크에 저장 
- 그러나 이렇게 개선한다고 해도, 한 대 서버로 부족한 때가 찾아온다. 
- 많은 데이터를 저장하려면 분산 키-값 저장소를 만들 필요가 있다.

### 분산 키-값 저장소  
- 분산 해시 테이블이라고도 불린다.
- 키-값 쌍을 여러 서버에 분산시킨다.  
- 분산 시스템을 설계할 때는 CAP 정리를 이해하고 있어야 한다. 

**CAP 정리**  
- 데이터 일관성(consistency), 가용성(availability), 파티션 감내(partition tolerance) 라는 세 가지 요구사항을 동시에 만족하는 분산 시스템을 설계하는 것은 불가능하다는 정리
- 각 요구사항의 의미는
  - 데이터 일관성: 분산 시스템에 접속하는 모든 클라이언트는 어떤 노드에 접속했느냐에 관계없이 언제나 같은 데이터를 보아야 함.
  - 가용성: 분산 시스템에 접속하는 클라이언트는 일부 노드에 장애가 발생해도 항상 응답을 받아야 한다.
  - 파티션 감내: 파티션은 두 노드 사이에 통신 장애가 발생하였음을 의미하고, 파티션 감내는 네트워크에 파티션이 생기더라도 시스템은 계속 동작해야 한다는 뜻
- CAP 정리는 3가지중에 2가지를 충족하려면 나머지 하나는 반드시 희생되어야 한다는 의미이다.
- 키-값 저장소는 어떤 2가지를 만족하느냐에 따라 다음과 같이 분류 된다.
  - CP 시스템: 가용성을 희생
  - AP 시스템: 데이터 일관성을 희생
  - CA 시스템: 파티션 감내를 희생. 그러나 보통 네트워크 장애는 피할 수 없는 일로 여겨져서, 실세계에 CA 시스템은 존재하지 않는다.
  

구체적인 사례를 살펴보자.  
분산 시스템에서 데이터는 보통 여러 노드에 복제되어 보관된다.  


![image](https://github.com/meokgu-skku/be/assets/28394879/ab2bb678-55fd-4f08-ab14-0fba438cdaae)  
- 위의 그림처럼 세 대의 복제(replica) 노드 n1,n2,n3에 데이터를 복제하여 보관하는 상황을 가정해보자. 

**이상적 상태**  
- 이상적 환경이면 네트워큭가 파티션되는 상황은 절대로 일어나지 않는다.
- n1에 기록된 데이터는 자동으로 n2, n3에 복제되므로 일관성과 가용성도 만족한다.  

**실세계의 분산 시스템**  
![image](https://github.com/sinkyoungdeok/TIL/assets/28394879/602fd61e-3548-47c8-b185-a2f09236d76d)
- 분산 시스템은 파티션 문제를 피할 수 없고, 파티션 문제가 발생하면 일관성과 가용성 사이에서 하나를 선택해야 한다.
- 위 그림은 n3에 장애가 발생하여 n1 및 n2와 통신할 수 없는 상황을 보여준 것이다.
- 클라이언트가 n1 또는 n2에 기록한 데이터는 n3에 전달되지 않는다.
- n3에 기록되었으나 아직 n1 및 n2로 전달되지 않은 데이터가 있다면 n1, n2는 오래된 사본을 갖고 있을 것이다.
- 가용성 대신 일관성을 선택하면, 불일치 문제를 피하기 위해 n1, n2에 대해 쓰기 연산을 중단시켜야한다. 즉, 가용성이 깨진다.
  - 은행권 시스템은 보통 데이터 일관성을 양보하지 않는다. ex) 온라인 뱅킹 시스템이 계좌 최신 정보를 출력하지 못하면 큰 문제다.
  - 파티션때문에 일관성이 깨질 수 있는 상황이 발생하면 해결되기전 까지 오류를 반환해야 한다.
- 일관성 대신 가용성을 선택하면, 낡은 데이터를 반환할 위험이 있더라도 계속 읽기 연산을 허용해야 한다.
  - n1, n2는 계속 쓰기 연산을 허용할 것이고, 파티션 문제가 해결된 뒤에 새 데이터를 n3에 전송한다.
- 분산 키-값 저장소를 만들 때는 그 요구사항에 맞도록 CAP 정리를 적용해야 한다.
- 면접을 볼 떄에는 면접관과 상의하고, 그 결론에 따라 시스템을 설계 하자.

**시스템 컴포넌트**  
키-값 저장소 구현에 사용될 핵심 컴포넌트들 및 기술들을 살펴보자.  
- 데이터 파티션
- 데이터 다중화(replication)
- 일관성(consistency)
- 일관성 불일치 해소(inconsistency resolution)
- 장애 처리
- 시스템 아키텍처 다이어그램
- 쓰기 경로
- 읽기 경로 

**데이터 파티션**  
대규모 애플리케이션의 경우 전체 데이터를 한 대 서버에 욱여넣는 것은 불가능하다.  
가장 단순한 해결책은 데이터를 작은 파티션들로 분할해서 여러 대 서버에 저장하는 것이다.  
데이터를 파티션 단위로 나눌 때는 다음 두가지 문제를 중요하게 따져야 한다.  
- 데이터를 여러 서버에 고르게 분산할 수 있는가
- 노드가 추가되거나 삭제될 때 데이터의 이동을 최소화할 수 있는가 
5장에서 다룬 안정해시로 이런문제를 풀기에 적합하다.  
안정 해시를 사용하여 데이터를 파티션하면 좋은점은 다음과 같다.  
- 규모 확장 자동화(automatic scaling): 시스템 부하에 따라 서버가 자동으로 추가되거나 삭제되도록 만들 수 있다.  (궁금한 것: 서버 추가되면 데이터는 어떻게 넣을까?)
- 다양성(heterogeneity): 각 서버의 용량에 맞게 가상 노드의 수를 조정할 수 있다. 다시 말해, 고성능 서버는 더 많은 가상 노드를 갖도록 설정할 수 있다.  

**데이터 다중화**  
![image](https://github.com/sinkyoungdeok/TIL/assets/28394879/ecc11ff6-0b97-4b1e-955c-80f8c175461e)  
- 높은 가용성과 안정성을 확보하기 위해서는 데이터를 N개 서버에 비동기적으로 다중화할 필요가 있다.  
- 여기서 N은 튜닝 가능한 값이다.
- N개를 선정하는 방법은
  - 어떤 키를 해시 링 위에 배치한 후, 그 지점으로부터 시계 방향으로 링을 순회하면서 만나는 첫 N개 서버에 데이터 사본을 보관한다.
  - 위 그림은 N=3으로 설정하여 key0는 s1,s2,s3에 저장된다.
- 그런데 가상 노드를 사용한다면 위와 같이 선택한 N개의 노드가 대응될 실제 물리 서버의 개수가 N보다 작아질 수 있다.  
  - 이 문제를 피하려면 노드를 선택할 때 같은 물리 서버를 중복 선택하지 않도록 해야 한다.
- 같은 데이터 센터에 속한 노드는 정전, 네트워크 이슈, 자연재해 등의 문제를 동시에 겪을 가능성이 있다.  
  - 따라서 안정성을 담보하기 위해 데이터의 사본은 다른 센터의 서버에 보관하고, 센터들은 고속 네트워크로 연결한다.

**데이터 일관성**  
여러 노드에 다중화된 데이터는 적절히 동기화가 되어야 한다.  
정족수 합의(Quorum Consensus) 프로토콜을 사용하면 읽기/쓰기 연산 모두에 일관성을 보장할 수 있다.  
관계된 정의부터 몇 가지 살펴보자.  
- N=사본 개수  
- W=쓰기 연산에 대한 정족수. 쓰기 연산이 성공한 것으로 간주되려면 적어도 W개의 서버로 부터 쓰기 연산이 성공했다는 응답을 받아야 함.
- R=읽기 연산에 대한 정족수. 읽기 연산이 성공한 것으로 간주되려면 적어도 R개의 서버로부터 응답을 받아야 함.

![image](https://github.com/sinkyoungdeok/TIL/assets/28394879/cef4026f-cab3-4213-8471-ff3d482d0b37)  
- 위의 그림은 N=3인 경우에 대한 예제.  
- W=1은 데이터가 한 대 서버에만 기록된다는 것은 아니고, 중재자가 최소 한 대 서버로부터 쓰기 성공 응답을 받아야 한다는 의미이다.  
  - 따라서 s3로부터 성공 응답을 받았다면, s0, s2로부터의 응답을기다릴 필요가 없다. 
  - 중재자는 클라이언트와 노드 사이에서 proxy 역할을 한다.
- W, R, N의 값을 정하는 것은 응답 지연과 데이터 일관성 사이의 타협점을 찾는 전형적인 과정이다. 
- W = 1 또는 R =1 인 구성의 경우 응답속도는 빠를 것이다.
- W 또는 R 값이 1보다 큰 경우에는 일관성은 증가하지만, 가장 느린 서버로부터의 응답을 기다려야 하므로 느려진다.  
- W+R > N 인 경우에는 강한 일관성이 보장된다. 
  - 일관성성을 보증할 최신 데이터를 가진 노드가 최소 하나는 겹칠 것이기 때문이다.  
- 면접 시에는 N,W,R 값을 어떻게 정해야 할까? 다음에 가능한 몇가지 구성을 제시했다.
  - R = 1, W = N: 빠른 읽기 연산에 최적화된 시스템
  - W = 1, R = N: 빠른 쓰기 연산에 최적화된 시스템
  - W + R > N: 강한 일관성이 보장된 (보통 N = 3, W=R=2)
  - W + R <= N: 강한 일관성이 보장되지 않음 

**일관성 모델**  
- 일관성 모델은 키-값 저장소를 설계할 때 고려해야 할 또 하나의 중요한 요소다.  
- 일관성 모델은 데이터 일관성의 수준을 결정하는데, 종류가 다양하다.  
  - 강한 일관성(strong consistency): 모든 읽기 연산은 가장 최근에 갱신된 결과를 반환한다. 즉, 클라이언트는 절대로 낡은 데이터를 보지 못한다.
  - 약한 일관성(weak consistency): 읽기 연산은 가장 최근에 갱신된 결과를 반환하지 못할 수 있다.  
  - 최종 일관성(eventual consistency): 약한 일관성의 한 형태로, 갱신 결과가 결국에는 모든 사본에 반영(즉, 동기화)되는 모델이다
- 강한 일관성을 달성하는 일반적인 방법은, 모든 사본에 현재 쓰기 연산의 결과가 반영될 떄까지 해당 데이터에 대한 읽기 쓰기를 금지하는 것이다.
  - 이 방법은 고가용성 시스템에는 적합하지 않다. 
- 다이나모, 카산드라 같은 저장소는 최종 일관성 모델을 택하고 있는데, 이번 장에서도 그 모델에 맞게 키-값 저장소를 설계할 것이다.
- 최종 일관성 모델을 따를 경우 쓰기 연산이 병렬적으로 발생하면 시스템에 저장된 값의 일관성이 깨어질 수 있는데, 이 문제는 클라이언트가 해결해야 한다.  
  - 클라이언트측에서 데이터의 버전 정보를 활용해 일관성이 깨진 데이터를 읽지 않도록 하는기법에 대해서 아래에서 살펴보자. 

**비 일관성 해소 기법:데이터 버저닝**  
- 데이터를 다중화하면 가용성은 높아지지만 사본 간 일관성이 깨질 가능성이 높아진다.  
- 버저닝(versioning)과 벡터 시계(vector clock)는 그 문제를 해소하기 위해 등장한 기술이다.  
- 버저닝은 데이터를 변경할 때마다 해당 데이터의 새로운 버전을 만드는것을 의미한다.  
- 따라서 각 버전의 데이터는 변경 불가능하다.
- 버저닝에 대해 알아보기 전에 우선 데이터 일관성이 깨지는지 예제를 통해 알아보자.  

![image](https://github.com/sinkyoungdeok/TIL/assets/28394879/78bc4f8a-5f4f-4ef6-bc6e-8fa8c2226d5f)  
- 위 그림과 같이 어떤 데이터의 사본이 노드 n1과 n2에 보관되어 있다고 하자.  
- 데이터를 가져오려는 서버1과 서버2는 get("name") 연산의 결과로 같은 값을 얻는다.  

![image](https://github.com/sinkyoungdeok/TIL/assets/28394879/16760a67-1c6c-4195-8421-419cea4a2e45)  
- 서버 1은 johnSanFranciso로 바꾸고, 서버 2는 jhonNewYork로 바꾸는데 이 두 연산은 동시에 이뤄진다고 해보자.
- 이제 우리는 충돌(conflict)하는 두 값을 갖게 되었다. 그리고 각각 버전을 v1, v2라고 하자.  
- 변경이 이뤄진 후에, 원래 값은 무시할 수 있어도 v1, v2 사이의 충돌은 해소하기 어려워 보인다.  
- 이 문제를 해결하려면, 충돌을 발견하고 자동으로 핵려해 낼 버저닝 시스템이 필요하다.  
- 벡터 시계(vector clock)는 이런 문제를 푸는데 보편적으로 사용되는 기술이다. 

지금부터 그 동작 원리를 살펴보자.  
- 벡터 시계는 [서버, 버전]의 순서쌍을 데이터에 매단 것이다.  
- 어떤 버전이 선행 버전인지, 후행 버전인지, 아니면 다른 버전과 충돌이 있는지 판별하는데 쓰인다.  
- 벡터 시계는 D([S1,v1], [S2,v2], ..., [Sn, vn])와 같이 표현한다고 가정하자. 
- D는 데이터이고, vi는 버전 카운터, Si는 서버 번호이다.  
- 만일 데이터 D를 서버 Si에 기록하면, 시스템은 아래 작업 가운데 하나를 수행해야 한다.  
  - [Si, vi] 가 있으면 vi를 증가시킨다
  - 그렇지 않으면 새 항목 [Si, 1]를 만든다.


![image](https://github.com/sinkyoungdeok/TIL/assets/28394879/f4b42f95-43a5-4d62-b595-b130afc8dc7b)  
1. 클라이언트가 데이터 D1을 시스템에 기록한다. 이 쓰기 연산을 처리한 서버는 Sx이다. 따라서 벡터 시계는 D1[(Sx, 1)]으로 변한다.
2. 다른 클라이언트가 데이터 D1을 읽고 D2로 업데이트한 다음 기록한다. D2는 D1에 대한 변경이므로 D1을 덮어쓴다. 이떄 쓰기 연산은 같은 서버 Sx가 처리한다고 가정하자. 벡터 시계는 D2([Sx, 2])로 바뀔 것이다. 
3. 다른 클라이언트가 D2를 읽어 D3로 갱신한 다음 기록한다. 이 쓰기 연산은 Sy가 처리한다고 가정하자. 벡터 시계 상태는 D3([Sx,2],[Sy,1])로 바뀐다.
4. 또 다른 클라이언트가 D2를 읽고 D4로 갱신한 다음 기록한다. 이때 쓰기 연산은 서버 Sz가 처리한다고 가정하자. 벡터 시계는 D4([Sx,2],[Sz,1])일 것이다.
5. 어떤 클라이언트가 D3, D4를 읽으면 데이터 간 충돌이 있다는것을 알게 된다. 이 충돌은 클라이언트가 해소한 후에 서버에 기록한다. 이 쓰기 연산을 처리한 서버는 Sx였다고 하자. 벡터 시계는 D5([Sx,3],[Sy,1],[Sz,1])로 바뀐다. 충돌이 일어났다는 것을 어떻게 감지하는지는 잠시 후에 자세히 살펴보자.  


- 벡터 시계를 사용하면 어떤 버전 X가 버전 Y의 이전 버전인지(따라서 충돌이 없는지) 쉽게 판단할 수 있다.  
- 버전 Y에 포함된 모든 구성요소의 값이 X에 포함된 모든 구성요소 값보다 같거나 큰지만 보면 된다.
  - ex) 벡터 시계 D([s0,1],[s1,1]) 은 D([s0,1],[s1,2])의 이전 버전이고, 충돌은 없다.
- 어떤 버전 X와 Y사이에 충돌이 있는지 보려면 Y의 벡터 시계 구성요소 가운데 X의 벡터 시계 동일 서버 구성요소보다 작은 값을 갖는 것이 있는지 보면된다.
  - ex) D([s0,1],[s1,2]) 와 D([s0,2],[s1,1])는 서로 충돌한다. 
- 그러나 벡터 시계를 사용해 충돌을 감지하고 해소하는 방법에는 두 가지 단점이 있다. 
  - 1) 충돌 감지 및 해소 로직이 클라이언트에 들어가므로, 클라 구현이 복잡해진다.
  - 2) [서버:버전]의 순서쌍 개수가 굉장히 빨리 늘어난다.  
    - 이 문제를 해결하려면 그 길이에 어떤 임계치를 설정하고, 임계치 이상으로 길어지면 오래된 순서쌍을 제거하도록 해야 하는데 
    - 이렇게하면 버전 간 선후 관계가 정확하게 결정될 수 없기 때문에 충돌 해소 과정의 효율성이 낮아진다.
    - 하지만 다이나모 데이터베이스에 관계된 문헌에 따르면 아마존은 실제 서비스에서 그런 문제가 벌어지는 것을 발견한 적이 없다고 한다.
    - 그러니 대부분의 기업에서 벡터 시계는 적용해도 괜찮은 솔루션일 것이다. 

**장애 처리**  
- 대다수 대규모 시스템에서 장애는 아주 흔한 사건이다.
- 따라서 장애를 어떻게 처리할 것인지는 굉장히 중요한 문제다.
- 이번 절에서 장애 감지 기법들을 먼저 살펴보고, 그다음으로 장애 해소 전략들을 짚어보자.

**장애 감지**  
- 분산 시스템에서는 한 대 서버가 A서버가 죽어도 바로 A서버를 장애처리 하지 않는다. 
- 보통 두 대 이상의 서버가 똑같이 서버 A의 장애를 보고해야 장애가 발생했다고 간주한다.  

![image](https://github.com/sinkyoungdeok/TIL/assets/28394879/7290d843-0921-4e78-9ab3-b31fb100ca5f)  
- 위 그림과 같이 모든 노드 사이에 멀티캐스팅 채널을 구축하는 것이 서버 장애를 감지하는 가장 손쉬운 방법이다.
- 하지만 이 방법은 서버가 많을 때 비효율적이다.



가십 프로토콜(gossip protocol) 같은 분산형 장애 감지 (decentralized failure detection) 솔루션을 새택하는 편이 보다 효율적이다.  
가십 프로토콜의 동작 원리는 다음과 같다.  
- 각 노드는 멤버십 목록(membership list)를 유지한다. 멤버십 목록은 각 멤버 ID와 그 박동 카운터(heartbeat counter) 쌍의 목록이다.  
- 각 노드는 주기적으로 자신의 박동 카운터를 증가시킨다.
- 각 노드는 무작위로 선정된 노드들에게 주기적으로 자기 박동 카운터 목록을 보낸다.
- 박동 카운터 목록을 받은 노드는 멤버십 목록을 최신 값으로 갱신한다.
- 어떤 멤버의 박동 카운터 값이 지정된 시간 동안 갱신되지 않으면 해당 멤버는 장애(offline) 상태인 것으로 간주한다.

![image](https://github.com/sinkyoungdeok/TIL/assets/28394879/9451ad34-86f5-4307-96a6-c23f4c9c46fa)  
- 위의 그림은 가십 프로토콜의 예시이다.  
- 노드 s0은 그림 좌측의 테이블과 같은 멤버십 목록을 가진 상태다.
- 노드 s0은 노드 s2의 박동 카운터가 오랫동안 증가되지 않았다는 것을 발견한다.
- 노드 s0은 노드 s2를 포함하는 박동 카운터 목록을 무작위로 선택된 다른 노드에게 전달한다 
- 노드 s3의 박동 카운터가 오랫동안 증가되지 않았음을 발견한 모든 노드는 해당 노드를 장애 노드로 표시한다.


**일시적 장애 처리**  
- 가십 프로토콜로 장애를 감지한 시스템은 가용성을 보장하기 위해 필요한 조치를 해야 한다. 
  - 엄격한 정족수(strict quorum) 접근법을 쓴다면, 읽기와 쓰기 연산을 금지해야 한다.
- 느슨한 정족수(sloppy quorum) 접근법은 이 조건을 완화하여 가용성을 높인다.
  - 정족수 요구사항을 강제하는 대신, 쓰기 연산을 수행할 W개의 건강한 서버와 읽기 연산을 수행할 R개의 건강한 서버를 해시 링에서 고른다. (장애 상태 서버는 무시)
- 네트워크나 서버 문제로 장애 상태인 서버로 가는 요청은 다른 서버가 잠시 맡아 처리한다. 
- 그동안 발생한 변경사항은 해당 서버가 복구되었을 때 일괄 반영하여 데이터 일관성을 보존한다. 
- 이를 위해 임시로 쓰기 연산을 처리한 서버에는 그에 관한 단서(hint)를 남겨둔다.  
- 따라서 이런 장애 처리 방안을 단서 후 임시 위탁(hinted handoff) 기법이라 부른다.  

![image](https://github.com/sinkyoungdeok/TIL/assets/28394879/45cb6391-e3db-4252-b320-3e5b287165b5)  
- 그림 예제를 보자.  
- 장애 상태인 노드 s3에 대한 읽기 및 쓰기 연산은 일시적으로 노드 s3가 처리한다.
- s2가 복구되면, s3는 갱신된 데이터를 s2로 인계할 것이다.


**영구 장애 처리**  
- 단서 후 임시 위탁 기법은 일시적 장애를 처리하기 위한 것이다. 영구적인 노드의 장애 상태는 어떻게 처리해야 할까? 
- 반-엔트로피(anti-entropy) 프로토콜을 구현하여 사본들을 동기화해보자.
- 반-엔트로피 프로토콜은 사본들을 비교하여 최신 버전으로 갱신하는 과정을 포함한다.
- 사본 간의 일관성이 망가진 상태를 탐지하고 전송 데이터의 양을 줄이기 위해서는 머클(Merkle) 트리를 사용할 것이다.
  - 해시트리라고도 불리는 머클트리는 각 노드에 그 자식 노드들에 보관된 값의 해시, 또는 자식 노드들의 레이블로부터 계산된 해시값을 레이블로 붙여두는 트리다. 
  - 해시 트리를 사용하면 대규모 자료 구조의 내용을 효과적이면서도 보안상 안전한 방법으로 검증할 수 있다.
- 키 공간(key space)가 1부터 12까지일 때 머클 트리를 만드는 예제를 한번 살펴보자. 일관성이 망가진 데이터가 위치한 상자는 다른 색으로 표시해두었다.

![image](https://github.com/sinkyoungdeok/TIL/assets/28394879/2041a0ab-3ae3-4e4c-b3cb-9bc6dda05ffe)  
- 1단계: 키 공간을 위와 같이 버킷으로 나눈다 (예제에선 4개의 버킷)

![image](https://github.com/sinkyoungdeok/TIL/assets/28394879/59433646-d793-45b3-a48f-793677623349)  
- 2단계: 버킷에 포함된 각각의 키에 균등 분포 해시(uniform hash) 함수를 적용하여 해시 값을 계산한다. 

![image](https://github.com/sinkyoungdeok/TIL/assets/28394879/5ac84796-4604-43e2-94ca-148a81facae1)  
- 3단계: 버킷별로 해시값을 계싼한 후, 해당 해시 값을 레이블로 갖는 노드를 만든다.

![image](https://github.com/sinkyoungdeok/TIL/assets/28394879/cf202c9e-f5ce-4ed3-aa5b-bf7db42ae7a5)  
- 4단계: 자식 노드의 레이블로부터 새로운 해시 값을 계싼하여, 이진 트리를 상향식으로 구성해 나간다.


- 이 두 머클 트리의 비교는 루트(root) 노드의 해시값을 비교하는 것으로 시작한다. 
- 루트 노드의 해시 값일 일치한다면 두 서버는 같은 데이터를 갖는 것이다.
- 그 값이 다른 경우에는 왼쪽 자식 노드의 해시 값을 비교하고, 그다음으로 오른쪽 자식 노드의 해시 값을 비교한다.
- 이렇게 하면서 아래쪽으로 탐색해 나가다 보면 다른 데이터를 갖는 버킷을 찾을 수 있으므로, 그 버킷들만 동기화하면 된다.  
- 머클 트리를 사용하면 동기화해야 하는 데이터의 양은 실제로 존재하는 차이의 크기에 비례할 뿐, 두 서버에 보관된 데이터의 총량과는 무관해진다.  
- 하지만 실제로 쓰이는 시스템의 경우 버킷 하나의 크기가 꽤 크다는 것은 알아 두어야 한다.  
- 가능한 구성 가운데 하나를 예로 들면 10(1B)개의 키를 백만 (1M)개의 버킷으로 관리하는 것인데, 그 경우 하나의 버킷은 1,000개 키를 관리하게 된다.

궁금한점: 데이터가 추가만 된다면 유효한데, 삭제나 업데이트는 어떻게 감지할까? -> 타임스탬프를 도입하거나 상태 플래그와 같은 추가적인 메커니즘을 사용하면 해결 가능


데이터 센터 장애 처리  
- 데이터 센터 장애는 정전, 네트어워크 장애, 자연재해 등 다양한 이유로 발생할 수 있다.  
- 데이터 센터 장애에 대응할 수 있는 시스템을 만들려면 데이터를 여러 데이터 센터에 다중화하는 것이 중요하다.
- 한 데이터센터가 완전히 망가져도 사용자는 다른 데이터 센터에 보관된 데이터를 이용할 수 있다.


**시스템 아키텍처 다이어그램**  
이 아키텍처의 주된 기능은 다음과 같다.  
- 클라이언트는 키-값 저장소가 제공하는 두 가지 단순한 API, 즉 get(key) 및 put(key, value)와 통신한다. 
- 중재자(coordinator)는 클라이언트에게 키-값 저장소에 대한 프락시(proxy) 역할을 하는 노드다.
- 노드는 안정 해시(consistent hash)의 해시 링(hash ring) 위에 분포한다.

![image](https://github.com/sinkyoungdeok/TIL/assets/28394879/200e98a8-f16d-4bb3-af90-5bcc874ee7b4)  
- 노드를 자동으로 추가 또는 삭제할 수 있도록, 시스템은 완전히 분산된다(decentralized)
- 데이터는 여러 노드에 다중화된다.
- 모든 노드가 같은 책임을 지므로, SPOF는 존재하지 않는다.

![image](https://github.com/sinkyoungdeok/TIL/assets/28394879/92129f87-0acf-469f-8f07-ce05b86ef030)  
- 완전히 분산된 설계를 채택했으므로, 모든 노드는 위 그림에 제시된 기능 전부를 지원해야 한다.

**쓰기 경로**  
![image](https://github.com/sinkyoungdeok/TIL/assets/28394879/5be2da84-75cd-49ae-99ac-b422db041f86)  
- 위 그림은 쓰기 요청이 특정 노드에 전달되면 무슨일이 벌어지는지를 보여준다.  
- 이 그림에서 보인 구조는 기본적으로 카산드라의 사례를 참고한 것이다.  
  
1. 쓰기 요청이 커밋 로그(commit log) 파일에 기록된다.
2. 데이터가 메모리 캐시에 기록된다.
3. 메모리 캐시가 가득차거나 사전에 정의된 어떤 임계치에 도달하면 데이터는 디스크에 있는 SSTable에 기록된다. 
   - SSTable은 Sorted-String Table이고 
   - <키,값>의 순서쌍을 정렬된 리스트 형태로 관리하는 테이블이다. 

**읽기 경로**  
![image](https://github.com/sinkyoungdeok/TIL/assets/28394879/c58248ab-038a-4aaf-8b0c-adeb92f77e99)  
- 읽기 요청을 받은 노드는 데이터가 메모리 캐시에 있는지부터 살핀다.  
- 있는 경우에는 데이터를 클라이언트에게 반환한다.

![image](https://github.com/sinkyoungdeok/TIL/assets/28394879/5e472010-2f8a-431a-851e-86c9cc6e2c87)  
- 데이터가 메모리에 없는 경우에는 디스크에서 가져온다.
- 어느 SSTable에 찾는 키가 있는지 알아낼 효율적인 방법이 필요할 것이다. 
- 이런 문제를 푸는데는 블룸 필터(Bloom filter)가 흔히 사용된다.

1. 데이터가 메모리에 있는지 검사한다. 없으면 2로 
2. 데이터가 메모리에 없으므로 블룸 필터를 검사한다.
3. 블룸 필터를 통해 어떤 SSTable에 키가 보관되어 있는지 알아낸다.
4. SSTable에서 데이터를 가져온다
5. 해당 데이터를 클라이언트에 반환한다.


### 요약  
- 기억을 되살리는 차원에서 분산 키-값 저장소가 가져야 하는 기능과 그 기능 구현에 이용되는 기술을 정리해보자.

| 목표/문제 | 기술 |
| --- | --- |
| 대규모 데이터 저장 | 안정 해시를 사용해 서버들에 부하 분산 |
| 읽기 연산에 대해 높은 가용성 보장 | 데이터를 여러 데이터센터에 다중화 |
| 쓰기 연산에 대한 높은 가용성 보장 | 버저닝 및 벡터 시계를 사용한 충돌 해소 |
| 데이터 파티션 | 안정 해시 | 
| 점진적 규모 확장성 | 안정 해시 |
| 다양성(heterogeneity) | 안정 해시 |
| 조절 가능한 데이터 일관성 | 정족수 합의(quorum consensus) | 
| 일시적 장애 처리 | 느슨한 정족수 프로토콜(sloppy quorum)과 단서 후 임시 위탁(hinted handoff) |
| 영구적 장애 처리 | 머클 트리(Merkle tree) |
| 데이터 센터 장애 대응 | 여러 데이터 센터에 걸친 데이터 다중화 |


## 7. 분산 시스템을 위한 유일 ID 생성기 설계 

- auto_increment 속성이 설정된 관계형 DB의 기본키를 쓰면 되지 않을까? 라고 생각할수도 있지만
- 분산 환경에서 이 접근법은 통하지 않는다. 
  - 데이터베이스 서버 한대로는 그 요구를 감당할 수 없고
  - 여러 데이터베이스 서버를 쓰는 경우에는 지연 시간(delay)을 낮추기가 무척 힘들다.

유일성이 보장되는 ID의 몇 가지 예를 보자


### 1단계: 문제 이해 및 설계 범위 확정 
- 시스템 설계 면접 문제를 푸는 첫 단계는 적절한 질문을 통해 모호함을 없애고 설계 방향을 정하는 것이다.  
- 다음은 면접관과 지원자 사이에 오갈 수 있는 질문과 답변의 예시다. 

지원자: ID는 어떤 특성을 갖나요?  
면접관: ID는 유일해야 하고, 정렬 가능해야 합니다.  
지원자: 새로운 레코드에 붙일 ID는 항상 1만큼 큰 값이어야 하나요?  
면접관: ID의 값은 시간이 흐름에 따라 커질 테지만 언제나 1씩 증가한다고 할 수는 없습니다. 다만 확실한 것은, 아침에 만든 ID보다는 저녁에 만든 ID가 큰 값을 갖는다는 점입니다.  
지원자: ID는 숫자로만 구성되나요?  
면접관: 그렇습니다.  
지원자: 시스템 규모는 어느 정도입니까?  
면접관: 초당 10,000 ID를 생성할 수 있어야 합니다.  

질문을 할 때는 요구사항을 이해하고 모호함을 해소하는 데 초점을 맞추어야 한다.  
이번 문제에 대한 답안이 만족해야 할 요구사항은 아래와 같다.  
- ID는 유일해야 한다.
- ID는 숫자로만 구성되어야 한다.
- ID는 64비트로 표현될 수 있는 값이어야 한다.  
- ID는 발급 날짜에 따라 정렬 가능해야 한다 
- 초당 10,000개의 ID를 만들 수 있어야 한다. 

### 2단계: 개략적 설계안 제시 및 동의 구하기   
분산 시스템에서 유일성이 보장되는 ID를 만드는 방법은 여러 가지다.  
- 다중 마스터 복제 (multi-master replication)
- UUID(Universally Unique Identifier)
- 티켓 서버 (ticket server)
- 트위터 스노플레이크 (twitter snowflacke) 접근법

이들 각각의 동작 원리와 장단점을 살펴보자  


**다중 마스터 복제**  
![image](https://github.com/sinkyoungdeok/TIL/assets/28394879/2d7f1464-10b4-408b-b5bf-1ffa0bc997f6)  
- 다중 마스터 복제는 대략 위의 그림과 같은 구성을 갖는다.  
- 이 접근법은 데이터베이스의 auto_increment 기능을 활용하는 것이다.  
- 다만 다음 ID의 값을 구할 때 1만큼 증가시켜 얻는 것이 아니라, k만큼 증가시킨다. (k = DB 수)
- 어떤 서버가 만들어 낼 다음 아이디는, 해당 서버가 생성한 이전 ID 값에 전체 서버의 수 2를 더한 값이다.  
- 이렇게하면 DB수를 늘리면 초당 생산 가능 ID 수도 늘릴 수 있기 때문에, 규모 확장성 문제를 어느정도 해결할 수 있다.
- 하지만 다음과 같은 중대한 단점이 있다.
  - 여러 데이터 센터에 걸쳐 규모를 늘리기 어렵다.
  - ID의 유일성이 보장되겠지만 그 값이 시간 흐름에 맞추어 커지도록 보장할 수는 없다.
  - 서버를 추가하거나 삭제할 때도 잘 동작하도록 만들기 어렵다

**UUID**  
- 유일성이 보장되는 ID를 만드는 또 하나의 간단한 방법.
- 컴퓨터 시스템에 저장되는 정보를 유일하게 식별하기 위한 128비트짜리 수  
- UUID 값은 충돌 가능성이 지극히 낮다.  
- UUID는 서버 간 조율 없이 독립적으로 생성 가능하다.

![image](https://github.com/sinkyoungdeok/TIL/assets/28394879/d54116c8-a95c-4a34-b68f-31c5997272ef)  
- 이 구조에서 각 웹 서버는 별도의 ID 생성기를 사용해 독립적으로 ID를 만들어낸다.

장점
- UUID를 만드는 것은 단순하다. 서버 사이의 조율이 필요 없으므로 동기화 이슈도 없다.
- 각 서버가 자기가 쓸 ID를 알아서 만드는 구조이므로 규모 확장도 쉽다. 

단점  
- ID가 128비트로 길다. 여기에서 요구사항은 64비트다.  
- ID를 시간순으로 정렬할 수 없다.  
- ID에 숫자 아닌 값이 포함될 수 있다.  

**티켓 서버**  
- 플리커(Flicker)는 분산 기본 키(distributed primary key)를 만들어 내기 위해 이 기술을 이용하였다. 

![image](https://github.com/sinkyoungdeok/TIL/assets/28394879/65483e6b-3be7-46bf-9c24-2625e3b2b0b6)  
- 이 아이디어의 핵심은 auto_increment 기능을 갖춘 데이터베이스 서버, 즉 티켓 서버를 중앙 집중형으로 하나만 사용하는 것이다.  

장점  
- 유일성이 보장되는 오직 숫자로만 구성된 ID를 쉽게 만들 수 있다.
- 구현하기 쉽고 ,중소 규모 애플리케이션에 적합하다.  

단점
- 티켓 서버가 SPOF가 된다. 
  - 이 서버에 장애가 발생하면, 해당 서버를 이용하는 모든 시스템이 영향을 받는다.  
  - 이 이슈를 피하려면 티켓 서버를 여러 대 준비해야 한다.  
  - 하지만 그렇게 하면 데이터 동기화 같은 새로운 문제가 발생할 것이다.  


**트위터 스노플레이크 접근법**  
- 지금까지 여러 ID 생성기 구현 방법을 살펴보았지만, 이번 장에서 풀어야할 문제의 요구사항을 만족시키는 것은 없었다.  
- 트위터는 스노플레이크라고 부르는 독창적인 ID생성 기법을 사용한다.  

![image](https://github.com/sinkyoungdeok/TIL/assets/28394879/cde07968-6224-45c0-b33a-55730d15ac3f)  
- ID를 바로 생성하는 대신, 각개 격파 전략(divide and conquery)을 먼저 적용해보자.  
- 생성해야 하는 ID의 구조를 여러 절(section)로 분할하는 것이다.  
- 각 절의 쓰임새를 살펴보면 
  - 사인(sign) 비트: 1비트를 할당. 지금으로서는 쓰임새가 없지만 나중을 위해 유보해둔다. 음수와 양수를 구별하는데 사용할 수 있다.
  - 타임 스탬프: 41비트를 할당한다. 기원 시각(epoch) 이후로 몇 밀리초가 경과했는지를 나타내는 값이다. 본 설계안의 경우는 기원 시각으로 트위터 스노플레이크 구현에서 사용하는 값인 1288834974657(Nov 04, 2010, 01:42:54 UTC에 해당)을 이용할 것이다. 
  - 데이터 센터 ID: 5비트를 할당한다. 따라서 2^5 = 32 개 데이터센터를 지원할 수 있다.
  - 서버 ID: 5비트 할당. 데이터센터당 32개 서버를 사용할 수 있다.
  - 일련번호: 12비트를 할당. 각 서버에서는 ID를 생성할 때마다 이 일련번호를 1만큼 증가시킨다. 이 값은 1밀리초가 경과할 때마다 0으로 초기화(reset)된다.


### 3단계: 상세 설계  

트위터 스노플레이크 접근법을 다시 보자.  
- 데이터 센터 ID, 서버 ID는 시스템이 시작할 때 결정되며, 일반적으로 시스템 운영 중에는 바뀌지 않는다.  
- 타임 스탬프나 일련번호는 ID 생성기가 돌고 있는 만들어지는 값이다.  

**타임스탬프**  
- ID 구조에서 가장 중요한 41비트를 차지하고 있다.  
- 타임스탬프는 시간이 흐름에 따라 점점 큰 값을 갖게 되므로, 결국 ID는 시간순으로 정렬 가능하게 될 것이다.  

![image](https://github.com/sinkyoungdeok/TIL/assets/28394879/c7200c1d-1172-4b9b-bea1-0ec70a4121f6)  
- 그림은 앞서 살펴본 ID 구조를 따르는 값의 이진 표현 형태로부터 UTC시각을 추출하는 예이다.  
- 이 방법을 역으로 적용하면 어떤 UTC 시각도 상술한 타임스탬프 값으로 변환할 수 있다.  
- 41비트로 표현할 수 있는 타임스탬프의 최댓값은 대략 69년에 해당한다.  
- 따라서 69년동안만 정상 동작하는데, 기원 시각을 현재에 가깝게 맞춰서 오버플로가 발생하는 시점을 늦춴호은 것이다.  
- 69년이 지나면 기원 시각을 바꾸거나 ID 체계를 다른 것으로 이전해야(migration) 한다.

**일련번호**  
- 12비트이므로, 2^12 = 4096개의 값을 가질 수 있다.  
- 어떤 서버가 같은 밀리초 동안 하나 이상의 ID를 만들어 낸 경우에만 0보다 큰 값을 갖게 된다.

궁금증) 

### 4단계: 마무리  
- 유일성이 보장되는 ID생성기 구현에 쓰일 수 있는 다양한 전략, 즉 다중 마스터 복제, UUID, 티켓 서버, 트위터 스노플레이크의 네 가지 방법을 살펴보았다.  
- 우리가 선택한 방식은 스노플레이크인데, 모든 요구사항을 만족하고 분산 환경에서 규모 확장이 가능했기 때문이다.  

설계를 진행하고 시간이 조금 남았다면 면접관과 다음을 추가로 논의할 수도 있을 것이다.  

- 시계 동기화(clock synchronization)
  - 이번 설계를 진행하면서 우리는 ID 생성 서버들이 전부 같은 시계를 사용한다고 가정하였다.
  - 하지만 이런 가정은 하나의 서버가 여러 코어에서 실행될 경우 유효하지 않을 수 있다. 
  - 여러 서버가 물리적으로 독립된 여러 장비에서 실행되는 경우에도 마찬가지다.
  - NTP(Network Time Protocol)은 이 문제를 해결하는 가장 보편적 수단이다. 
- 각 절(section)의 길이 최적화
  - 예를 들어 동시성(concurrency)이 낮고 수명이 긴 애플리케이션이라면 일련번호 절의 길이를 줄이고 타임스탬프 절의 길이를 늘리는 것이 효과적일 수 있다.
- 고가용성
  - ID 생성기는 필수 불가결(mission critical) 컴포넌트 이므로 아주 높은 가용성을 제공해야 한다.

 
## 9. 웹 크롤러 설계 

- 웹 크롤러는 로봇(robot) 또는 스파이더(spider)라고도 부른다.
- 검색 엔진에서 널리 쓰는 기술로, 웹에 새로 올라오거나 갱신된 컨텐츠를 찾아내는 것이 주된 목적
  - 콘텐츠는 웹 페이지, 이미지나 비디오, 또는 PDF 파일이 될 수 있음 
- 웹 크롤러는 몇 개 웹 페이지에서 시작해서 링크를 따라 나가면서 새로운 컨텐츠를 수집한다. 

![image](https://github.com/sinkyoungdeok/TIL/assets/28394879/47409148-efe5-4e4b-a526-e3e8544c1d32)  
- 위 그림은 크롤러 과정을 시각적 예제로 정리한 내용

크롤러는 다양하게 이용된다.  

- 검색 엔진 인덱싱
  - 크롤러의 가장 보편적인 용례
  - 크롤러는 웹 페이지를 모아 검색 엔진을 위한 로컬 인덱스를 만듬
  - 일례로 Googlebot은 구글 검색 엔진이 사용하는 웹 크롤러
- 웹 아카이빙
  - 나중에 사용할 목적으로 장기보관하기 위해 웹에서 정보를 모으는 절차
  - 많은 국립 도서관이 크롤러를 돌려 웹사이트를 아카이빙하고 있음. 
- 웹 마이닝
  - 웹의 폭발적 성장세는 데이터 마이닝 업계에 전례 없는 기회다.
  - 웹 마이닝을 통해 인터넷에서 유용한 지식을 도출해 낼 수 있는 것
- 웹 모니터링
  - 크롤러를 사용하면 인터넷에서 저작권이나 상표권이 침해되는 사례를 모니터링할 수 있음.


### 1단계: 문제 이해 및 설계 범위 확정
